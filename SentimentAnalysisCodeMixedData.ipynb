{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisCodeMixedData.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21b2fc14f4304dc8b9a08d963e81e695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18a0f6b3f64d426b9662b6318f817751",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddb23e6d629940f1b39783e413e57df2",
              "IPY_MODEL_4e25081673df45dda0c4f88f9cd44a3b",
              "IPY_MODEL_a229cc173d844d4cb887e7a07c8b8758"
            ]
          }
        },
        "18a0f6b3f64d426b9662b6318f817751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddb23e6d629940f1b39783e413e57df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4ffcab3697446e189a7ab5241f98ee3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a600b232e7ba4db198b59db9dabb4212"
          }
        },
        "4e25081673df45dda0c4f88f9cd44a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_510aaa69ed6b43fea90462c17c71543a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_451a48349f414c2685633b2164ac1701"
          }
        },
        "a229cc173d844d4cb887e7a07c8b8758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78814bdf47f34ec6ad250afdc9335021",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 208k/208k [00:00&lt;00:00, 2.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bc6ef41fa184e6cb9d2fa057cb38a81"
          }
        },
        "f4ffcab3697446e189a7ab5241f98ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a600b232e7ba4db198b59db9dabb4212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "510aaa69ed6b43fea90462c17c71543a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "451a48349f414c2685633b2164ac1701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78814bdf47f34ec6ad250afdc9335021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bc6ef41fa184e6cb9d2fa057cb38a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52b76687132c4e288dc770ec5b2dd101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9bb9e691af247ea9057beecc19688a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_767418201eec4227a0fcf7424e42d259",
              "IPY_MODEL_efe2f9a07a784e92848cf85404c26a51",
              "IPY_MODEL_e12ac806067b43fb9b2c6613a8ab44ec"
            ]
          }
        },
        "e9bb9e691af247ea9057beecc19688a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "767418201eec4227a0fcf7424e42d259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e920da5ee587448f9b2cb266aef4302d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_593c1f63ebc344f885672d672513852a"
          }
        },
        "efe2f9a07a784e92848cf85404c26a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04a324da78c6458ab7ab66d4134853c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7c234dce9ee443a9acbdc002e01846c"
          }
        },
        "e12ac806067b43fb9b2c6613a8ab44ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f01edf5aeaa9445884318c664c3adcf6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 917B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3078c7b8555d4d4b88f00e86dfcf6b05"
          }
        },
        "e920da5ee587448f9b2cb266aef4302d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "593c1f63ebc344f885672d672513852a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04a324da78c6458ab7ab66d4134853c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7c234dce9ee443a9acbdc002e01846c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f01edf5aeaa9445884318c664c3adcf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3078c7b8555d4d4b88f00e86dfcf6b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ffdab5788e146feb4795762b581c445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aaf20852083a4a0296ac6d9051671227",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d5b6b4398b74f79bdf73d57c2de04e8",
              "IPY_MODEL_d56640e7448a4826aa657ffea32214cb",
              "IPY_MODEL_204a66c9e456417a86c4c74ca28f95bb"
            ]
          }
        },
        "aaf20852083a4a0296ac6d9051671227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d5b6b4398b74f79bdf73d57c2de04e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07dbcfeb60c248759c07076b43cdc62d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b46d02bf70a447b9983715605de5bc8"
          }
        },
        "d56640e7448a4826aa657ffea32214cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ec9eff2d248442a8ded1e2a30329cfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4431246e22824fedb556575713fa5de6"
          }
        },
        "204a66c9e456417a86c4c74ca28f95bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51e74f48ac1a4a86b9b6e365963f3d56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 426k/426k [00:00&lt;00:00, 2.72MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22fe6af5a364402d877aa9924ec40379"
          }
        },
        "07dbcfeb60c248759c07076b43cdc62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b46d02bf70a447b9983715605de5bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ec9eff2d248442a8ded1e2a30329cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4431246e22824fedb556575713fa5de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51e74f48ac1a4a86b9b6e365963f3d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22fe6af5a364402d877aa9924ec40379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "866537df10204b689c8546fcf2fc8d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a4be2528bb04e87aa34c1b413b7142d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e02d66ff3ed34e4e9fefb2054e99f77c",
              "IPY_MODEL_1ab57fe80a55437ebc2b16fdb75c67b9",
              "IPY_MODEL_3875b134357c465d85a9fa8ff6798bd0"
            ]
          }
        },
        "8a4be2528bb04e87aa34c1b413b7142d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e02d66ff3ed34e4e9fefb2054e99f77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_445c56ec9ba84d0ea300f1ccc909f116",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d5b2723a90b48beac6012cfdcdef238"
          }
        },
        "1ab57fe80a55437ebc2b16fdb75c67b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fe0424c061b4f21b304178309d832ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11a585c3f05d41f8b140f65b7adf37d5"
          }
        },
        "3875b134357c465d85a9fa8ff6798bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b48ff1a10d984d8481bf6bdfd4ac73b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 10.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c595fb8a5e74ac2af6ffa27febc56e7"
          }
        },
        "445c56ec9ba84d0ea300f1ccc909f116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d5b2723a90b48beac6012cfdcdef238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fe0424c061b4f21b304178309d832ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11a585c3f05d41f8b140f65b7adf37d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b48ff1a10d984d8481bf6bdfd4ac73b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c595fb8a5e74ac2af6ffa27febc56e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c88128a47f4a4c8bac7105abbef8567d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca1b409f0eac49419963c8bb3c2c68d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90355c4ac92243d48382a5205469d61e",
              "IPY_MODEL_4df425f936cc4daead753e6d8f17264a",
              "IPY_MODEL_1d3834e186a448048698f77829f9f4c5"
            ]
          }
        },
        "ca1b409f0eac49419963c8bb3c2c68d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90355c4ac92243d48382a5205469d61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b329d0e473ae41b0b3ce0369299aae86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0133857b35e24837a6a8b26a85199f90"
          }
        },
        "4df425f936cc4daead753e6d8f17264a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f83b410dd0ae46c095e13d6eb29e079b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b1433a2cc2f4175ba0cbcc3b5e71fae"
          }
        },
        "1d3834e186a448048698f77829f9f4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_109fee285f4146518539ac374e75f26e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 416M/416M [00:12&lt;00:00, 33.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35034a5cb1954774946116bbef377021"
          }
        },
        "b329d0e473ae41b0b3ce0369299aae86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0133857b35e24837a6a8b26a85199f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f83b410dd0ae46c095e13d6eb29e079b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b1433a2cc2f4175ba0cbcc3b5e71fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109fee285f4146518539ac374e75f26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35034a5cb1954774946116bbef377021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny4EVItrQZwc"
      },
      "source": [
        "import re\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqeR1IrHjNZ2"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc7vTAs5jNaO"
      },
      "source": [
        "import numpy as numpy\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf_FEu17jNaS"
      },
      "source": [
        "To visualize the data in the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE1Nz9fvjNaU"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvqvY-aYjNaY"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.utils import shuffle \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNMc_IqZjNaa"
      },
      "source": [
        "NLP Preprocessing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Ev8_FjjNab"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgtYOfL4jNac"
      },
      "source": [
        "import re\n",
        "import random\n",
        "import gensim"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUiRz2pvjNae"
      },
      "source": [
        "from collections import Counter\n",
        "import unicodedata as udata\n",
        "import string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bafYTpXLjNag"
      },
      "source": [
        "checking the versions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWXyragEjNah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c101ea21-fae1-4c0e-9fe7-d65e31f5fc5c"
      },
      "source": [
        "print(sklearn.__version__)\n",
        "print(matplotlib.__version__)\n",
        "print(numpy.__version__)\n",
        "print(pd.__version__)\n",
        "print(nltk.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22.2.post1\n",
            "3.2.2\n",
            "1.19.5\n",
            "1.1.5\n",
            "3.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCuOhD7vRYGN"
      },
      "source": [
        "#File read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9S0AoKT3uJ9c",
        "outputId": "a4e94b56-026f-4624-baee-52ff1de9451e"
      },
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1iW8-Y9aePxyEhq1L7-_ldD9L-TzDd_Qb','Code_mixed_data.txt',quiet=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Code_mixed_data.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C952WDrXSgFZ"
      },
      "source": [
        "fp = open(\"Code_mixed_data.txt\", 'r')\n",
        "\n",
        "X_train_csnli=[]\n",
        "\n",
        "tweets = []\n",
        "tweets_label = []\n",
        "for line in fp:\n",
        "  lst = []\n",
        "  lst = line.strip().split('\\t')\n",
        "  tweets.append(lst[1])\n",
        "  tweets_label.append(lst[2])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUdxsOqhYp6d"
      },
      "source": [
        "tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrtW7M3RRWJ3",
        "outputId": "8d518684-4aeb-4a61-8270-5efae54ad829"
      },
      "source": [
        "len(tweets_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3879"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yBxqGKVRgVz"
      },
      "source": [
        "# clean_tweet_texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnvxZexijNa_"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()\n",
        "\n",
        "pat1 = r'@[A-Za-z0-9_]+'        # remove @ mentions from tweets\n",
        "pat2 = r'https?://[^ ]+'        # remove URLs from tweets\n",
        "combined_pat = r'|'.join((pat1, pat2)) #addition of pat1 and pat2\n",
        "www_pat = r'www.[^ ]+'         # remove URLs from tweets\n",
        "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",   # converting words like isn't to is not\n",
        "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
        "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
        "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
        "                \"mustn't\":\"must not\"}\n",
        "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
        "\n",
        "def tweet_cleaner(text):  # define tweet_cleaner function to clean the tweets\n",
        "    soup = BeautifulSoup(text, 'lxml')    # create beautiful soup object\n",
        "    souped = soup.get_text() \n",
        "    #print('tweer_clean','\\n')\n",
        "    #print(text,'\\n')  # get only text from the tweets \n",
        "    #print(souped,'\\n')\n",
        "    try:\n",
        "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")    # remove utf-8-sig code\n",
        "    except:\n",
        "        bom_removed = souped\n",
        "    stripped = re.sub(combined_pat, '', bom_removed) # calling combined_pat\n",
        "    #print(stripped,'\\n')\n",
        "    stripped = re.sub(www_pat, '', stripped) #remove URLs\n",
        "    #print(stripped,'\\n')\n",
        "    lower_case = stripped.lower()      # converting all into lower case\n",
        "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case) # converting words like isn't to is not\n",
        "    #print(neg_handled,'\\n')\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)       # will replace # by space\n",
        "    #print(letters_only,'\\n')\n",
        "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1] # Word Punct Tokenize and only consider words whose length is greater than 1\n",
        "    return (\" \".join(words)).strip() # join the words"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8lV0kGWdjNbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca12caa7-4684-4f8c-a89b-b0ea4d289405"
      },
      "source": [
        "#Note that we have 1600000 instances. But processing so many instances will take a very very long time.\n",
        "#Hence, restricting to rather 50000 instances.\n",
        "limit=len(tweets_label)\n",
        "import time; \n",
        "ms = time.time()\n",
        "#nums = [0,400000,800000,1200000,1600000] # used for batch processing tweets\n",
        "#nums = [0, 9999]\n",
        "clean_tweet_texts = [] # initialize list\n",
        "for i in range(0,limit): # batch process 1.6 million tweets \n",
        "    if i % 2000==0:\n",
        "        print(i, time.time()-ms)\n",
        "    clean_tweet_texts.append(tweet_cleaner(tweets[i]))  # call tweet_cleaner function and pass parameter as all the tweets to clean the tweets and append cleaned tweets into clean_tweet_texts list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 7.700920104980469e-05\n",
            "2000 0.4889364242553711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW0RtQ5NFrnR"
      },
      "source": [
        "clean_tweet_texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8pH1AJ-jNbD"
      },
      "source": [
        "# Tokenizing tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daNBU-2JjNbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296fd113-92fe-42e2-86ab-f13e8b70d4bd"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAuo3C-0jNbF"
      },
      "source": [
        "tokenize word in clean_tweet_texts and append it to word_tokens list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hHdpFW-jNbG"
      },
      "source": [
        "word_tokens = [] # initialize list for tokens\n",
        "for word in clean_tweet_texts:  # for each word in clean_tweet_texts\n",
        "    word_tokens.append(word_tokenize(word)) #tokenize word in clean_tweet_texts and append it to word_tokens list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaX_XeQ4J0Fs"
      },
      "source": [
        "word_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airSvVTPjNbI"
      },
      "source": [
        "# Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibbpKs1jNbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f41f2f3-ad1a-4a78-df17-c43f6ddc67f8"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDc8T7cpjNbK"
      },
      "source": [
        "df1 = [] # initialize list df1 to store words after lemmatization\n",
        "from nltk.stem import WordNetLemmatizer # import WordNetLemmatizer from nltk.stem\n",
        "lemmatizer = WordNetLemmatizer() # create an object of WordNetLemmatizer\n",
        "for l in word_tokens: # for loop for every tokens in word_token\n",
        "    b = [lemmatizer.lemmatize(q) for q in l] #for every tokens in word_token lemmatize word and giev it to b\n",
        "    df1.append(b) #append b to list df1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFc1whKoJxPr"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LBiBO3BjNbL"
      },
      "source": [
        "clean_df1 =[] # initialize list clean_df1 to join word tokens after lemmatization\n",
        "for c in df1:  # for loop for each list in df1\n",
        "    a = \" \".join(c) # join words in list with space in between and give it to a\n",
        "    clean_df1.append(a) # append a to clean_df1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZEtRVtJRnpx"
      },
      "source": [
        "#Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgOtR7BpKMi0"
      },
      "source": [
        "from sklearn.model_selection  import train_test_split #from sklearn.cross_validation import train_test_split to split the data into training and tesing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(tweets, tweets_label, test_size = 0.20, random_state= 1) # split the data into traing and testing set where ratio is 80:20"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIRgSFllFrgO"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvOq7_C7I1CS"
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjGCVn0GI0_L"
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "X_train_flair = [Sentence(tweet) for tweet in X_train]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_XcFQSoI08l"
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "X_test_flair = [Sentence(tweet) for tweet in X_test]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xonw--_UI06P",
        "outputId": "de191c5e-0b74-47d8-c340-62997d152094"
      },
      "source": [
        "X_test_flair"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence: \"rafu apko nhi bolna already wo dechyka hota h\"   [− Tokens: 9],\n",
              " Sentence: \"Handsom to hai mera bhai bhai he mera\"   [− Tokens: 8],\n",
              " Sentence: \"Baat kidhr hogi\"   [− Tokens: 3],\n",
              " Sentence: \"advanced eid mubarak\"   [− Tokens: 3],\n",
              " Sentence: \"Bhai shaadi b kroge ya randwe hi mroge\"   [− Tokens: 8],\n",
              " Sentence: \"Yr tum sab ko bahut takleef he bhai ki sadi . .. se . .. heiiiiinn ?\"   [− Tokens: 17],\n",
              " Sentence: \"modi ji apko sahi dimag ko me salute karta hu\"   [− Tokens: 10],\n",
              " Sentence: \"Hi bizy man ap hum sy kaha baat karo gy apko razan Mubarak hooo eid par SMG zaror karna plz plz bye\"   [− Tokens: 22],\n",
              " Sentence: \"Assalaam waalaikum bhaijaan ...\"   [− Tokens: 4],\n",
              " Sentence: \"Pagalo aa gae bus chalo ghus jao bus me jiyada aur rahy yaha to phir apka koi ilaj nhi\"   [− Tokens: 19],\n",
              " Sentence: \"5000comment in 5minute\"   [− Tokens: 3],\n",
              " Sentence: \"BAJRANGI BHAIJAAN 700 CRORE ! !\"   [− Tokens: 6],\n",
              " Sentence: \"Sir meri ek hi ichha h apse milna\"   [− Tokens: 8],\n",
              " Sentence: \"Mjh say bat karo na sweeeto 1 ber bus 1 ber\"   [− Tokens: 11],\n",
              " Sentence: \"Sir ji aap se bat karna hai hame\"   [− Tokens: 8],\n",
              " Sentence: \"Hay sallumeya eid mubark ho\"   [− Tokens: 5],\n",
              " Sentence: \"Salllu tumhe pta bhi h ki tum iss red pathani kurte me kya jabardast lag rahe ho .... koi bhi ladki mar jaaye tumhare liye to ... ummmmaaahhhh ?\"   [− Tokens: 29],\n",
              " Sentence: \"salman khan ji you looking owsm i love you salman me bta nhi skti ki me apki kitni bri fan hu ... .\"   [− Tokens: 23],\n",
              " Sentence: \"bhai ki bat hi alag hai . . . sb se hat k . . . bhai salman . . .\"   [− Tokens: 21],\n",
              " Sentence: \"assalamualaikum sallu bhai jumma mubarak ho sallu bhai twitter par mai hi ho aapko masages karti ho\"   [− Tokens: 17],\n",
              " Sentence: \"plz aayeye sir jhuth bole to smjh lena aap ek meri jitni achi fan gwa doge aap sir\"   [− Tokens: 18],\n",
              " Sentence: \"bhai tum shahi ho\"   [− Tokens: 4],\n",
              " Sentence: \"Harami kanjer insaan\"   [− Tokens: 3],\n",
              " Sentence: \"V good Modi ji aap lege rahe hum aapke sath he\"   [− Tokens: 11],\n",
              " Sentence: \"Bhai logo sbse bda dharm insaniyat usko follow karo\"   [− Tokens: 9],\n",
              " Sentence: \"bhai ap helpful prson ho sb ko pta h pr ap ki nazae me hlpful prsn kon h\"   [− Tokens: 18],\n",
              " Sentence: \"Oo salman sale ku bohat ghamand ayi musalmaano ku bola ki musalman koy bi nahi dekhe tho bi chalegi meri film bolke bola\"   [− Tokens: 23],\n",
              " Sentence: \"Abe tu ye sab kisse bat kar rhi hai yar\"   [− Tokens: 10],\n",
              " Sentence: \"Super duper hit.rahegi bhai\"   [− Tokens: 4],\n",
              " Sentence: \"Sir swach bharat mission ko gawon se shahro ki taraf lao Sir mission ki jinmedaari nagar nigam or parishd ko uttardaitav do Thanks\"   [− Tokens: 23],\n",
              " Sentence: \"haye Sallu .... tussi gr8 ho ....... .\"   [− Tokens: 8],\n",
              " Sentence: \"tumne muje msg kya tha plz batao please\"   [− Tokens: 8],\n",
              " Sentence: \"sallu yar 6 baj gaye. .\"   [− Tokens: 6],\n",
              " Sentence: \"Bhaiiii jaaaan waiting fr uuuu . ...:(:(:(:(:(:,(:,(:,(\"   [− Tokens: 7],\n",
              " Sentence: \"kya hua apka wada woh kasam woh irada\"   [− Tokens: 8],\n",
              " Sentence: \"The Logical Indian Kuch bhi likhte ho . . ek bar soch bhi liya kro likhne se pehle\"   [− Tokens: 18],\n",
              " Sentence: \"Jaanma main bol rahi hu ki,tum mere twits dekho :/\"   [− Tokens: 10],\n",
              " Sentence: \"Hiiiiiii salman sir\"   [− Tokens: 3],\n",
              " Sentence: \"Is mein koi shak nhi ho gi salman bhai ki movie ho or record na ho\"   [− Tokens: 16],\n",
              " Sentence: \"Aapki film k liye aapko dher sari shubhkamna\"   [− Tokens: 8],\n",
              " Sentence: \"Bhai log maine abi suna newz me salman bhai bole jitne v mri fan hn wo Nrzz na ho I 'm just coming esa hi bole. .\"   [− Tokens: 27],\n",
              " Sentence: \"aapko late aane ki aadat hai me janta hun ... 4baje bhi sayad start nahi hoga ...\"   [− Tokens: 17],\n",
              " Sentence: \"kamal karte ho salman Ji\"   [− Tokens: 5],\n",
              " Sentence: \"Aap great ho modi ji aapki wajah se hamara sir fakar se ucha ho gaya dunia me jay ho\"   [− Tokens: 19],\n",
              " Sentence: \"Asalmwale coom bhaijaan\"   [− Tokens: 3],\n",
              " Sentence: \"hello sar g keshe ho aap\"   [− Tokens: 6],\n",
              " Sentence: \"Aur WO achi ladki hai\"   [− Tokens: 5],\n",
              " Sentence: \"sab ki aan sab ki saan aagya bajrangi bhaijaan\"   [− Tokens: 9],\n",
              " Sentence: \"Salman khan sir suna ha ap PAKISTAN ah rahy ha\"   [− Tokens: 10],\n",
              " Sentence: \"Wah sir g ab desh sahi hatho me gya h apko dekh kar aisa hi lagata h\"   [− Tokens: 17],\n",
              " Sentence: \"Tension leneka nehi # BHAIJAAN .\"   [− Tokens: 6],\n",
              " Sentence: \"gGuyssss meri profile picture kesi leg rahi hai. .?? ?\"   [− Tokens: 10],\n",
              " Sentence: \"4 baj gaye bhai\"   [− Tokens: 4],\n",
              " Sentence: \"sabki jaan salman khan .\"   [− Tokens: 5],\n",
              " Sentence: \"wowwwwww omg aaj kyu nahi ............ love u salman\"   [− Tokens: 9],\n",
              " Sentence: \"Tek ha ap is.waqt bht bzi ha\"   [− Tokens: 7],\n",
              " Sentence: \"waah todi or request krke dekho tb bhi nhi dekhai dege salman bhai\"   [− Tokens: 13],\n",
              " Sentence: \"Bhai jaan kha ho Salman khan\"   [− Tokens: 6],\n",
              " Sentence: \"bhaijaan jaldi aao fb par waiting 4 U\"   [− Tokens: 8],\n",
              " Sentence: \"ara bhai jaan hum bhi to aap ke bhai hai chote bhai jaan ...\"   [− Tokens: 14],\n",
              " Sentence: \"Unstoppable modi sir\"   [− Tokens: 3],\n",
              " Sentence: \"ye bhosdiwale bhagne vale nhi bc mc harami sale suwar ki olad\"   [− Tokens: 12],\n",
              " Sentence: \"Salman tum baishram ho pahlai Nam ka Matlab janlo pir samjo gai\"   [− Tokens: 12],\n",
              " Sentence: \"Bhai 5 mint rhegaye\"   [− Tokens: 4],\n",
              " Sentence: \"paye kuppi puthe vichil\"   [− Tokens: 4],\n",
              " Sentence: \"Sallu bhai mera tharafse ramzan mubarak ho\"   [− Tokens: 7],\n",
              " Sentence: \"Sonya tum ladka ho ya ldki jaldi btao ek kam h tum se\"   [− Tokens: 13],\n",
              " Sentence: \"Bhai tum tention mat lo apke real fans jo pata ye ghatia harqat kisi aur ki hai , we have faith on u bhaiiii ...? ?\"   [− Tokens: 26],\n",
              " Sentence: \"kha ho yrrr . 4:36 bhi ho gye . . nxt year 4bje aaoge kya\"   [− Tokens: 15],\n",
              " Sentence: \"Modi ji aachi suruwat hai skill India program we heartly congratulated .\"   [− Tokens: 12],\n",
              " Sentence: \"Ekdum Zakaaas hai sab. .\"   [− Tokens: 5],\n",
              " Sentence: \"bhai duva me yad.mahi\"   [− Tokens: 4],\n",
              " Sentence: \"Kutta harami madar chod bighrat salman to agar mje mil jai teri maa bhin ek kardonga\"   [− Tokens: 16],\n",
              " Sentence: \"Gud luck ji. . allah aapko sari khushiyo say navajay .. sayad aap humko bhul ghai lakinhamari saash rukh jayghi hum ushkya baad bhi aapko nahi bhulayghay. . allah hafis\"   [− Tokens: 30],\n",
              " Sentence: \"Bas dil pak ho bhale duinya kuch b kahe\"   [− Tokens: 9],\n",
              " Sentence: \"Mami papaa , aur bacha party aur Sab kaise hai\"   [− Tokens: 10],\n",
              " Sentence: \"piz contect me\"   [− Tokens: 3],\n",
              " Sentence: \"aap mere gao ki kahani p ek film bana do ...\"   [− Tokens: 11],\n",
              " Sentence: \"Sala hrami muslmano ka dushman badnam kiya hai Muslman ko kalank hai kabrustan mai tera paisa kaam nahi aayega balki # aamaal aor sabse pahle # imaan # pakka hai ya nahi\"   [− Tokens: 32],\n",
              " Sentence: \"Sir , Namaskar . Mai Bihar se hun aur aapka jabardash prasansak hu , Aap jo desh ke liye niswarth bav se kam kar rahe hai , aapko sadaib best p.m ke roop me jana jaega . salute to you sir .\"   [− Tokens: 42],\n",
              " Sentence: \"Bhai sab ko pagal samjha h kha ho\"   [− Tokens: 8],\n",
              " Sentence: \"nic song . bhi jan\"   [− Tokens: 5],\n",
              " Sentence: \"Hum log Jarur dekhenge aapka movie. .\"   [− Tokens: 7],\n",
              " Sentence: \"Salman ki diwaniya muj se ek baar chat krlo plzz ..... .\"   [− Tokens: 12],\n",
              " Sentence: \"Salmon bhai mai Apki boooooohat bari fan hn .\"   [− Tokens: 9],\n",
              " Sentence: \"? belive of course buddy ... i believe in your heart ... hameshaa buddy hameshaaa .... i love uuu < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3 < 3\"   [− Tokens: 405],\n",
              " Sentence: \"Nice pic abdul rashid saleem ( salman khan )\"   [− Tokens: 9],\n",
              " Sentence: \"aapka har andaz hi anokha hai janaab\"   [− Tokens: 7],\n",
              " Sentence: \"Bhaijaan app ki film k liye bohot bohot badhai\"   [− Tokens: 9],\n",
              " Sentence: \"Or uske khe bina uski baat samajh jate h\"   [− Tokens: 9],\n",
              " Sentence: \"Respected sir aap aaj pure Bharat ki ummid ho ... ek naya savera aapne hi janta ko dikhaya he ... ap dhup bhi nikaliye ...\"   [− Tokens: 25],\n",
              " Sentence: \"Aatma aur mun ki pavitrata ki jhalak hai is beti ki aawaz mei , khush raho beti .\"   [− Tokens: 18],\n",
              " Sentence: \"Sale ne muslmano ko chalenge kiya ki tumhare bina hit karunga\"   [− Tokens: 11],\n",
              " Sentence: \"Bhai comedy . Laavo na ... aap comedy with kapil me jitna hase ho .. utna haste hue pehle nahi dekha\"   [− Tokens: 21],\n",
              " Sentence: \"Hello koi hai ?\"   [− Tokens: 4],\n",
              " Sentence: \"jo ganda log hai woh ganda hi rahega according to pychology u cant change anyones behavior woh act karege par change nhi hote !\"   [− Tokens: 24],\n",
              " Sentence: \"bhak chutiya sala bhosrdi k shar gairat naam ki koi chiz nhi kya re tujme\"   [− Tokens: 15],\n",
              " Sentence: \"bhai apke is blockbuster movie bajrangi bhaijaan ke bare me kuch gadhe na jane kya kya bakbas kr rahe hai aur ahmedabad me to movie ki release pr ban lagane ke liye appeal bhi ki hai ap kya kahoge bhai\"   [− Tokens: 40],\n",
              " Sentence: \"hiii ab to 4 baj gye\"   [− Tokens: 6],\n",
              " Sentence: \"as salam walekum salman g apke sab fan ko pata h k aal kavi v kisiko hrt nhi kar sakte ho allah se dua h k apko hr musibat se bachae or buri najar se v\"   [− Tokens: 36],\n",
              " Sentence: \"Bollywood king my bro salman khan\"   [− Tokens: 6],\n",
              " Sentence: \"Ashu Sing tumhari saat howa hoga tum logo ka Mandira mai haaaaaaaaa\"   [− Tokens: 12],\n",
              " Sentence: \"sonya khan ek hijda musalmaan hai isey apna gender ni pata\"   [− Tokens: 11],\n",
              " Sentence: \"aap ke whtasup no. de do uspe bat karengai .... .\"   [− Tokens: 11],\n",
              " Sentence: \"salman sir aap apna ek kisi film mein Internationl rockstar Imran khan ko Singing ka mouka dijiye\"   [− Tokens: 17],\n",
              " Sentence: \"Supar hit bahi\"   [− Tokens: 3],\n",
              " Sentence: \"khash ap mjy ad kr kr .... i know esa ap kro gy ni ... .\"   [− Tokens: 16],\n",
              " Sentence: \"Kabi nahe deka relpy wait mat karo\"   [− Tokens: 7],\n",
              " Sentence: \"Kaha reh gye\"   [− Tokens: 3],\n",
              " Sentence: \"love uuu shallluuuuu\"   [− Tokens: 3],\n",
              " Sentence: \"jai bajrang bali. .\"   [− Tokens: 4],\n",
              " Sentence: \"Gr8 .... I love salman ..... challenge bhi good or challenge dene vala bhi good ....... .\"   [− Tokens: 17],\n",
              " Sentence: \"Eid ki party kahape milu bhai\"   [− Tokens: 6],\n",
              " Sentence: \"Bhai aapke baare mein koi kuch bhi kahe hame kuch farak nahi padta aap hamare bhai ho allah aap ki movie ko super kare jumma mubarak bhai khuda hafiz\"   [− Tokens: 29],\n",
              " Sentence: \"mujhe to pata hi nahi raha bat ho bhi rahi hai sorry jaa rahi hu bye\"   [− Tokens: 16],\n",
              " Sentence: \"Yo yo ka song hona chaiye tha\"   [− Tokens: 7],\n",
              " Sentence: \"bhai Eid mubarak advance kOi que . nahi puchne k liye tum jiyO hazarO saal allah bless yOu saal bhar saal\"   [− Tokens: 21],\n",
              " Sentence: \"May pm supar dupar nmo nmo\"   [− Tokens: 6],\n",
              " Sentence: \"Bajrangi bhaijaan is awsome\"   [− Tokens: 4],\n",
              " Sentence: \"bhai ap boht ache hn Allah ap khush rkhe\"   [− Tokens: 9],\n",
              " Sentence: \"Bhai bajrangi bhaijan to samjho ki HIT HAI\"   [− Tokens: 8],\n",
              " Sentence: \"Grt super star sallu bhai\"   [− Tokens: 5],\n",
              " Sentence: \"Jaao apne fans se baat karlo sab wait kare h\"   [− Tokens: 10],\n",
              " Sentence: \"Love u salmaan khan ji love u so much mithuuuuu ... mmuuaahh\"   [− Tokens: 12],\n",
              " Sentence: \"Nich musalman kis ko bola pehle apne aap ko dekh tu aaj jaha par hai un musamano ki vajah se hai . Samga.hamko dhamki deta hai kon dekhna chahega ye sadi movie\"   [− Tokens: 32],\n",
              " Sentence: \"ok boss apka hukum sir ankho pe\"   [− Tokens: 7],\n",
              " Sentence: \"modiji yehi voh desh hai jo hume aur mazbut banayenge\"   [− Tokens: 10],\n",
              " Sentence: \"bhai ap Hollywood movie kab kar rahe ho ?? ?\"   [− Tokens: 10],\n",
              " Sentence: \"Bhai kaise ho ?\"   [− Tokens: 4],\n",
              " Sentence: \"aisi ummeed nhi thi aapse bhaijaan . . DIL tod diya sbka :-(\"   [− Tokens: 13],\n",
              " Sentence: \"BiNa muslim Ki hit karke dikhyenge hm\"   [− Tokens: 7],\n",
              " Sentence: \"j banda kam kar raha hai ham maze le rahe hai jab sey india ke pm bane hai tab sey laga gai great man in the world ......... best pm in the world .... . only one on one ..... .\"   [− Tokens: 41],\n",
              " Sentence: \"Chal ba tharke\"   [− Tokens: 3],\n",
              " Sentence: \"kahi aisa to nhi bhai ki aap hume direct ye news doge ki aapki shadi bhot saal pehle ho chuki he n wo apne top secret rakha hai ?? ?\"   [− Tokens: 30],\n",
              " Sentence: \"bhai 4bje ayenge\"   [− Tokens: 3],\n",
              " Sentence: \"Apka kya khna PM ji\"   [− Tokens: 5],\n",
              " Sentence: \"Bhaijaan kamaal karte ho\"   [− Tokens: 4],\n",
              " Sentence: \"Tumne bhi kabhi saath nhi diyaa to mai akhir galat ho he gai cograss\"   [− Tokens: 14],\n",
              " Sentence: \"sir plz london aajoa plz\"   [− Tokens: 5],\n",
              " Sentence: \"salu bhi i your biggest fan jai bajrangi bhaijaan\"   [− Tokens: 9],\n",
              " Sentence: \"desh gourav badha rahe ho ayushman bhav\"   [− Tokens: 7],\n",
              " Sentence: \"Namsthe sir jai gurudhev\"   [− Tokens: 4],\n",
              " Sentence: \"Pakistan kyo jayega salman\"   [− Tokens: 4],\n",
              " Sentence: \"kisse karenge bro aapke to fan bhi bhut hai\"   [− Tokens: 9],\n",
              " Sentence: \"salman sir for u dabe mein daba dabe mein cake mera piyare salman sir cororo mein aik\"   [− Tokens: 17],\n",
              " Sentence: \"Bhadra hai sala\"   [− Tokens: 3],\n",
              " Sentence: \"Salman ji apka favorite gAna konsa hai bajrangi bhaijan film ka ???? ?\"   [− Tokens: 13],\n",
              " Sentence: \"Hamare desh ko aage badhane vale , logo me utsah jagane , narendra modi ji ko bhagvan hamesha khush rakhe .\"   [− Tokens: 21],\n",
              " Sentence: \"sir 2 gnte ho gaye ans nae aya\"   [− Tokens: 8],\n",
              " Sentence: \"Salmaaannnn pls baat karo\"   [− Tokens: 4],\n",
              " Sentence: \"mere bare me itna mat socho me dil me aata hu smjh me nhi\"   [− Tokens: 14],\n",
              " Sentence: \"kaya huya , kaha hai app,hum logo ko murga to nehe banareha hai ?\"   [− Tokens: 14],\n",
              " Sentence: \"sir m aapka chuta sa fan hu par kuch bhe kar sakta hu\"   [− Tokens: 13],\n",
              " Sentence: \"koi dusraa naam nai mila kya , is se pehle bhi Hero naami kayi filme pit chuki hai. .\"   [− Tokens: 19],\n",
              " Sentence: \"Bhaiya me bhi kuch karna chata hu pliZz 1 chans me Bhai\"   [− Tokens: 12],\n",
              " Sentence: \"O Ho bhai kal kaise niklega\"   [− Tokens: 6],\n",
              " Sentence: \"Thank you sir apka yatra se desh ko jarur fayada hoga hame garv hai app par aur apaki nitiyo par\"   [− Tokens: 20],\n",
              " Sentence: \"Bhaijan apke sath dekhni hai filmBajrangi bhaijann\"   [− Tokens: 7],\n",
              " Sentence: \"salman ap ko kabi b achhi intresting story wali films kyu nhe milee jis trha shahrukh ya amir ko milti ha\"   [− Tokens: 21],\n",
              " Sentence: \"Pk ?????...... agar bhagwan ko pujne ke liye ek chhoti si murti ki jarurat ni hai to tum bahanchod hizdo ko itne bade maszid ki kya jarurat hoti hai DHILE LAND KI PAIDAISHO ?? ?\"   [− Tokens: 35],\n",
              " Sentence: \"Apne naam se khan hatalo\"   [− Tokens: 5],\n",
              " Sentence: \"kaha ho .... aap salman\"   [− Tokens: 5],\n",
              " Sentence: \"Bekaar hoe gi\"   [− Tokens: 3],\n",
              " Sentence: \"Teri maa ki chuth . . film riles ka raha hai bahan chood . Eid . par kiyu . Nikal raha hai\"   [− Tokens: 22],\n",
              " Sentence: \"allah kare is khabis ki movie flop ho\"   [− Tokens: 8],\n",
              " Sentence: \"Aswlkm sahre hogye apki\"   [− Tokens: 4],\n",
              " Sentence: \"hell0 salman khan ... kesy h ap. .? ?\"   [− Tokens: 9],\n",
              " Sentence: \"Hy salman bhai\"   [− Tokens: 3],\n",
              " Sentence: \"Baccho k Dilon dimag ko satya k raste pe lane k liya Is geet ko schoolo me vandana k rup me anivarya karna chaheye .\"   [− Tokens: 25],\n",
              " Sentence: \"Meri ma apko bhot yaad karti he bhai\"   [− Tokens: 8],\n",
              " Sentence: \"chl ht salman\"   [− Tokens: 3],\n",
              " Sentence: \"sir itna to koi apni girlfriend ka b wait nae krta pta nae ap ans kyn nae d rhe\"   [− Tokens: 19],\n",
              " Sentence: \"Kya haal hain. . pawan kumar chaturvedi g. . urf . bajrangi bhai bhajaan\"   [− Tokens: 14],\n",
              " Sentence: \"Tere awaaz kutta ke awaaz Sam hi chor muslman hi to\"   [− Tokens: 11],\n",
              " Sentence: \"Sir i love u . MAIN aapka bhot bada faan hun,sir . Aap jo T-shart pehnte ho mujhe dedo Sir . Main HARYANA se hun Sir ji.my No. Sir 9991865726\"   [− Tokens: 30],\n",
              " Sentence: \"Humari sabhayata humari pehchaan ...\"   [− Tokens: 5],\n",
              " Sentence: \"BJP youth ki skill niche video me dekhiye .\"   [− Tokens: 9],\n",
              " Sentence: \"Trailer dhaaaansu hai yaar\"   [− Tokens: 4],\n",
              " Sentence: \"Hum dil de chuke sanam ... .\"   [− Tokens: 7],\n",
              " Sentence: \"bhai,tu kaha hain\"   [− Tokens: 3],\n",
              " Sentence: \"Kutte ki nhi sunni h koi bat\"   [− Tokens: 7],\n",
              " Sentence: \"meri baat par kisi bhi hamazade ko koi bhi doubt ho shock se aye mere village\"   [− Tokens: 16],\n",
              " Sentence: \"Bhaijaan of bollywod salman bhai\"   [− Tokens: 5],\n",
              " Sentence: \"bhai mera rply jarur krna pehle hi bta du ;-) apne khud hi bola hai main sare comment padhta hu ye v pdh lia hoga apne :- D\"   [− Tokens: 28],\n",
              " Sentence: \"apka fan ho bangladesh me plz cal sallu bhai met u + 8801719447771 cal bhai\"   [− Tokens: 15],\n",
              " Sentence: \"Hellooooo 6 mint upar ho gayyyyyy\"   [− Tokens: 6],\n",
              " Sentence: \"bhai jaan jai bajrangbali apki movie jarur blockbuster hogi\"   [− Tokens: 9],\n",
              " Sentence: \"pahle sahi se islam ka meaning sikh lo tum aur apne pita ji ko bhi sikhao\"   [− Tokens: 16],\n",
              " Sentence: \"abhi tk kyu nhi aye aap salman sir ??$$$$ dieing to tlc to u ...... .\"   [− Tokens: 16],\n",
              " Sentence: \"md.intjar.malik . bajrangi.bhijane . . i love.you . ( 786 ) . bhijane.apki.film . no : 1 hogi . bhijane.mujko call.karo . 8868026194 .\"   [− Tokens: 24],\n",
              " Sentence: \"Bina musalman ke hit ho jaye ga ye film samje\"   [− Tokens: 10],\n",
              " Sentence: \"Bohot accha hai . Aaj ki party mari taraf se , sab ko bolo utre flak se . Nice\"   [− Tokens: 19],\n",
              " Sentence: \"Sale kafir salam mat kar ... namaste kar\"   [− Tokens: 8],\n",
              " Sentence: \"Ramzan me sabki madad karte ho aap isiliye vo aaye the\"   [− Tokens: 11],\n",
              " Sentence: \"gold aur silver ke shear kharid ke bhul jao agar aage chal kar kabhi koi us businesses me jana chahe to shears bhech kar original kharidle nahi to wo rahega aise hi\"   [− Tokens: 32],\n",
              " Sentence: \"Superb Song & Supper-Dupper Hit Movie jb koi nek kaam krne niklta h to khuda bhi uska sath deta h apne to 1 chhoti bachchi ko uske apno s milana chaha isme to sari Kaynat apka sth degi\"   [− Tokens: 38],\n",
              " Sentence: \"Bhaijan tumara fon nombar chaie do na eid Mubarak bolne ka\"   [− Tokens: 11],\n",
              " Sentence: \"Madar Salman nai chalegi film\"   [− Tokens: 5],\n",
              " Sentence: \"plzz m apke rep ka w8 krri hu or krti rhugiii pkkkaaa\"   [− Tokens: 12],\n",
              " Sentence: \"Bhai jaan ko salaam\"   [− Tokens: 4],\n",
              " Sentence: \"Bhai kese hum ap se bat karsakeing. . Salman Khan\"   [− Tokens: 10],\n",
              " Sentence: \"Eid Mubarak bajrangi bhijaan\"   [− Tokens: 4],\n",
              " Sentence: \"Eid kab hain ? Jis din Salman ki filim release hoti hai .\"   [− Tokens: 13],\n",
              " Sentence: \"Haa hme bharosha h bhai\"   [− Tokens: 5],\n",
              " Sentence: \"Sir kya aap fir kashmir aavoge plz reply\"   [− Tokens: 8],\n",
              " Sentence: \"Bhaijaan aap kaa ek reply mere liye bohot important hai kyuki mai aapka bhakt hu\"   [− Tokens: 15],\n",
              " Sentence: \"kya hua sir ?\"   [− Tokens: 4],\n",
              " Sentence: \"Hlo sir kya aap kbhi mujhse baat krege kuchh hai jo aapse share krna chahti hu\"   [− Tokens: 16],\n",
              " Sentence: \"Bahut achchhakarya aur bahut achchha Hamara sarkar\"   [− Tokens: 7],\n",
              " Sentence: \"Reply plz bhai\"   [− Tokens: 3],\n",
              " Sentence: \"salman aap to hmare jaise ho eek baar kuch bolo\"   [− Tokens: 10],\n",
              " Sentence: \"Itne fan 's ko nervous kar k aap so kaise sakte ho\"   [− Tokens: 12],\n",
              " Sentence: \"Iss bar BJP ka kutta Muslim pe dhabba aanne wala hai eid k din jaha b ye kutta aayega jute mar k bhagao sale k ghar me ghusu\"   [− Tokens: 28],\n",
              " Sentence: \"Yar ji karrha h\"   [− Tokens: 4],\n",
              " Sentence: \"hii bhaijaan ... ab intjaar ni ho rha h ... apse baat karni h\"   [− Tokens: 14],\n",
              " Sentence: \"bhai jan duaa hei k appki film sooper dooper hit ho .\"   [− Tokens: 12],\n",
              " Sentence: \"okk bhai jaan . ..:)\"   [− Tokens: 5],\n",
              " Sentence: \"inbox ma bat karo sallu\"   [− Tokens: 5],\n",
              " Sentence: \"Sher kabhi darta nahi aur mera bhai sher hai love you bhai jaan\"   [− Tokens: 13],\n",
              " Sentence: \"Arey yrr jaldi kro wait kr kr ke dimag ka dahi ho gya\"   [− Tokens: 13],\n",
              " Sentence: \"Salman sir . Mera aims pura kardo me aapse milna chahta hu mujh se mil lijiye\"   [− Tokens: 16],\n",
              " Sentence: \"luv u salman muhhhh\"   [− Tokens: 4],\n",
              " Sentence: \"avitak 4pm hua nehi kya ?\"   [− Tokens: 6],\n",
              " Sentence: \"abe tm log nhi manoge tikhi mirchi wala nasta kraunga sb ko tbhi theek hoge ..... tb salman salman nhi pani pani chillana smjhe\"   [− Tokens: 24],\n",
              " Sentence: \"allaha aapk sath hai bhai\"   [− Tokens: 5],\n",
              " Sentence: \"Huhhh Watse our time .... . 3:30 se 4:00 Or ab tk ata pta nhi\"   [− Tokens: 15],\n",
              " Sentence: \"Party with salman & bebo kon miss krega\"   [− Tokens: 8],\n",
              " Sentence: \"AJA SHAM HONE AYI .... MOUSAM NE DI ANGRAIIII ....??? ? Plz reply me BB ....... LOVE U CHO MUCH ...????...... taktae rah te tujhko sanjh savere .... love u my BIG BOSS .... BB\"   [− Tokens: 35],\n",
              " Sentence: \"Helo. . bhia kaise ho ...! ! :)\"   [− Tokens: 8],\n",
              " Sentence: \"Love you love you salman bhai\"   [− Tokens: 6],\n",
              " Sentence: \"mission acchha hai bas lagu sahi se ho\"   [− Tokens: 8],\n",
              " Sentence: \"Sojaa yrr boor mtkr Alia Khan\"   [− Tokens: 6],\n",
              " Sentence: \":'( :'( :'( :'( :'( tum gande pati ho bhot gande I hate u I really hate u\"   [− Tokens: 18],\n",
              " Sentence: \"aap Kavi hamare orissa me to aao\"   [− Tokens: 7],\n",
              " Sentence: \"just awesome bonding pawan-munni\"   [− Tokens: 4],\n",
              " Sentence: \"salman ji ap kaha ho.plz ajao\"   [− Tokens: 6],\n",
              " Sentence: \"bhai kabhi to apne pas bhi to dekho , khudko bhul jaoge he he\"   [− Tokens: 14],\n",
              " Sentence: \"Sir kya mujh gareeb ko aik reply melay ga plz .... ?\"   [− Tokens: 12],\n",
              " Sentence: \"Mene kitni bar smjhaya tha rat ko chashma mt nikala kro animals njr ate hye ap ko firr\"   [− Tokens: 18],\n",
              " Sentence: \"aaj ki party bhaijaan ki tarf se fb par\"   [− Tokens: 9],\n",
              " Sentence: \"as salam alaikom :) aur intezar nai hota plz cm fast\"   [− Tokens: 11],\n",
              " Sentence: \"sir aap ki movies ka asar hai\"   [− Tokens: 7],\n",
              " Sentence: \"Bhai aapko sabke comment mile honge par mai ye aapse kahna chahta hu ki aap eid par mere ghar aaao or sewainya kha lo or ek bahut jaruri baat aapko batana h mujhe aapke reply ka wait rahega\"   [− Tokens: 38],\n",
              " Sentence: \"Bhai sabko reply kaise karoge\"   [− Tokens: 5],\n",
              " Sentence: \"Bhai esa mat karo\"   [− Tokens: 4],\n",
              " Sentence: \"Wait karana achi baat nahi hoti hai bhai ... . Bhai sirf rona baki hai\"   [− Tokens: 15],\n",
              " Sentence: \"Bahan chood teri\"   [− Tokens: 3],\n",
              " Sentence: \"Future ki baat mat karo . Hamara aaj bigad raha hai .\"   [− Tokens: 12],\n",
              " Sentence: \"Kya bat hai bhai\"   [− Tokens: 4],\n",
              " Sentence: \"tum achi acting krta h\"   [− Tokens: 5],\n",
              " Sentence: \"bhai kaha ho ap\"   [− Tokens: 4],\n",
              " Sentence: \"Salman bhai bas tum hi tum ho industry me jo chaye rahate ho aur dusara kai nahi\"   [− Tokens: 17],\n",
              " Sentence: \"nice bhai mai jarur aaunga\"   [− Tokens: 5],\n",
              " Sentence: \"Koi kitana bhi virodh kare hum movie Dekhenge ... because hame pata hai ki salman sir sab dharmo ko manate hai support karte hai aur koi galat kam nahi kar sakte ... love u salman sir\"   [− Tokens: 36],\n",
              " Sentence: \"Last replyyyyy plzz plzzz plzzzz\"   [− Tokens: 5],\n",
              " Sentence: \"BaH Guruji Kya style hai apka duniyako hila ke chhore hain .\"   [− Tokens: 12],\n",
              " Sentence: \"3.58 ... . ohhh cant wait :)\"   [− Tokens: 7],\n",
              " Sentence: \"bhi aapke movie ka besabri se wait kr rha hu aur mera aasa hai ki iss sal recod tut jayega ...\"   [− Tokens: 21],\n",
              " Sentence: \"AISA MATT KAROO\"   [− Tokens: 3],\n",
              " Sentence: \"salman bhai abi dabanng 3 ke shuts ke liye satara mai hai , so next time fans\"   [− Tokens: 17],\n",
              " Sentence: \"Oho tumare ankha tumare nak tumare lips kasm sa mar hi daloga ?\"   [− Tokens: 13],\n",
              " Sentence: \"jb aana hi ni tha to\"   [− Tokens: 6],\n",
              " Sentence: \"Kya karu samaj nhi aara bhot neend aari hai par namaaz is very important s\"   [− Tokens: 15],\n",
              " Sentence: \"Jai jai bajrangi bali tod de dushman ki nali . seen fisrt day fisrt show amazing movie\"   [− Tokens: 17],\n",
              " Sentence: \"arre ap to aaynge nhi hm ja rhe h .... .\"   [− Tokens: 11],\n",
              " Sentence: \"Aapse baat karna chahta hu bhai . bahut badi problem mae hu.aapki help chahta hu\"   [− Tokens: 15],\n",
              " Sentence: \"bhai mko.farq ni pdta\"   [− Tokens: 4],\n",
              " Sentence: \"4 bj gye hai kb aaoge online\"   [− Tokens: 7],\n",
              " Sentence: \"Hi salman i 'm sameer baloch in balochistan i 'm biggggg fan of you\"   [− Tokens: 14],\n",
              " Sentence: \"mananiy pradhan mantriji apko salam our ramajan eid mubarak\"   [− Tokens: 9],\n",
              " Sentence: \"I love u salman khan ek bar apsa milna cahti hu ya mara sapna ha bas ek bar love u love u love u love u love u so mach salman khan\"   [− Tokens: 32],\n",
              " Sentence: \"Kamal karte ho bajrangi bhaiya itna intzar ;-)\"   [− Tokens: 8],\n",
              " Sentence: \"Salman vai pls apne dare rakey. . vai app ko boss boss lage ga. .\"   [− Tokens: 15],\n",
              " Sentence: \"Aj ki party ... bhabi ki taraf se sallu bhai ...? ?\"   [− Tokens: 12],\n",
              " Sentence: \"avi aap ajaona plz\"   [− Tokens: 4],\n",
              " Sentence: \"Bhai Tere samne koi nahi bhai u r gret bhai\"   [− Tokens: 10],\n",
              " Sentence: \"sab bekar h .... . koi nhi aane wala .... . salman nhi aayega\"   [− Tokens: 14],\n",
              " Sentence: \"Salman bhai apne kuch bola tha shayad\"   [− Tokens: 7],\n",
              " Sentence: \"Ap se Sirf ek swal krunga bhi jaan\"   [− Tokens: 8],\n",
              " Sentence: \"ofcourse salman isme sochna kaisa. .\"   [− Tokens: 6],\n",
              " Sentence: \"plzz aajaao yar .... itna enry roza rkhne me ktm nahi hoti. . jitni apka w8 krne me ho rhi h .... plzz come na ..... plzzzz ... .\"   [− Tokens: 29],\n",
              " Sentence: \"Hlw Bhaijan.Bajrangi Bhaijan ko le kar apka kya opeksha hai ? Is film me aap hanuman jika vokt ho ap kay real zindegi me hanuman jiko mante ho ?\"   [− Tokens: 29],\n",
              " Sentence: \"Aisa PM naa hua hai aur naa hee hoga kabhi . .\"   [− Tokens: 12],\n",
              " Sentence: \"Onliy dabang bhai\"   [− Tokens: 3],\n",
              " Sentence: \"Hum Bihar ka to jeet gaye aur UP ka election jeeta dena.Abhi to hum 12seaton se jeete hai hume aur humen 65seaton se jeeta dena .\"   [− Tokens: 26],\n",
              " Sentence: \"Aate aaz bhai\"   [− Tokens: 3],\n",
              " Sentence: \"jb talak ap na aaoge m na jaunga FB se\"   [− Tokens: 10],\n",
              " Sentence: \"Salman khan Teri maa ki chuth aur Teri bahan ki chood\"   [− Tokens: 11],\n",
              " Sentence: \"mast bhai jaan\"   [− Tokens: 3],\n",
              " Sentence: \"Musalmaan kabhi aage se vaar ni karta hamesha hijdo ki tarah pichhe se vaar karta hai,Pakistan ko hi dekh lo Muslim hijdo ka desh Hahahahahahaha\"   [− Tokens: 25],\n",
              " Sentence: \"Ham log apane aap ko bhagy sali samajte hai ki desh ko aap jaise PM mile jay hind\"   [− Tokens: 18],\n",
              " Sentence: \"Sallu bhai reply do na us ladki ko plz ye mera izzat ka sawal hai plz. . plz. . plz. .\"   [− Tokens: 21],\n",
              " Sentence: \"Pta h log kitna pagal h apko milney ko\"   [− Tokens: 9],\n",
              " Sentence: \"Eid ke din salman apni maiya chudae\"   [− Tokens: 7],\n",
              " Sentence: \"Katrina ranvir ke saath hai. . tum kya kor rahe ho\"   [− Tokens: 11],\n",
              " Sentence: \"Apkeliya masig salman\"   [− Tokens: 3],\n",
              " Sentence: \"Bhaii aao na kha ho\"   [− Tokens: 5],\n",
              " Sentence: \"Aap ki baat hum sab ke sath :-) ;-) :- D\"   [− Tokens: 11],\n",
              " Sentence: \"oye fake id # salman _ khan tera to public # acount hai ... real hai to # page se reply mar\"   [− Tokens: 22],\n",
              " Sentence: \"Salman Khan bhai ap ko likes or comments km milte hain shah rukh khan ki nisbat\"   [− Tokens: 16],\n",
              " Sentence: \"Bhai jaan majhe le rahe ho malum h\"   [− Tokens: 8],\n",
              " Sentence: \"Sacha bharat INDIA\"   [− Tokens: 3],\n",
              " Sentence: \"Allah aapko khush rakhe or aap yun hi Blockbuster Films dete rahen or logo ko Entertain krte rahen Ham sab ki naik khwaishat or duaen aapke saaath hain ...\"   [− Tokens: 29],\n",
              " Sentence: \"Film se fursat nahi roza ka khak rakhe ge salman bhai\"   [− Tokens: 11],\n",
              " Sentence: \"Han bro roza to rahkata hun\"   [− Tokens: 6],\n",
              " Sentence: \"Kis kis ko rply denge salman ... uffffff .... jisko salman bahut achha lagta hain usko dena ... .\"   [− Tokens: 19],\n",
              " Sentence: \"Sallu bhai kisi ko rply nhi krte or humlog bewkufo k jese sallu bhai sallu bhai kiya krte h\"   [− Tokens: 19],\n",
              " Sentence: \"Are Bhai ko kuch bat bolo . q ke hum ya pe bohat sare fan ho . is k liye aanahi raha hai . waise b bo kitne k sath bat karenge .\"   [− Tokens: 33],\n",
              " Sentence: \"Bohat achi ha ap thek hai ramazan k se gura ha\"   [− Tokens: 11],\n",
              " Sentence: \"kya 3:30 bola tha\"   [− Tokens: 4],\n",
              " Sentence: \"Hi salman bhai i am sameer thandi hawa ka jhokha ...\"   [− Tokens: 11],\n",
              " Sentence: \"Koun bolhata hai Saadi nahi hogi .. meri aur Salman ki saadi hogi 2016 .. October .. first week :) :)\"   [− Tokens: 21],\n",
              " Sentence: \"Kis khushi me tyar hojae bhai shadi ki party dere ho\"   [− Tokens: 11],\n",
              " Sentence: \"Ã – nline hoya nahi\"   [− Tokens: 5],\n",
              " Sentence: \"aaj ki party bhai k taraf se\"   [− Tokens: 7],\n",
              " Sentence: \"Kas ma aipka khas friend rahta our aipka karib rahata.kas ma kis.kis ma aip ka kareb hota.mubark ho.aipko roja .\"   [− Tokens: 20],\n",
              " Sentence: \"salman bhai am ur big fan ... . am from paaaakkkiiissstan ... . plzzz plzzzzz plzz plzzzz rply me one time .... . plzzzzz waiting\"   [− Tokens: 25],\n",
              " Sentence: \"Bhot sahi bhai ... Bhai bhai ... . :)\"   [− Tokens: 9],\n",
              " Sentence: \"I love sallu bhai jaan\"   [− Tokens: 5],\n",
              " Sentence: \"Great PM sahab yeh sab only hmare modi ji hi kar skte h\"   [− Tokens: 13],\n",
              " Sentence: \"ap hi sach boldo ye sab photo wagaire sahi hai ki nhi\"   [− Tokens: 12],\n",
              " Sentence: \"salman khan to ghode bech ke sogaye hoge . aur yahan machi market banare sab . sojao salman ke deewano\"   [− Tokens: 20],\n",
              " Sentence: \"Kise khushi main party de hai aap ne apne kaha tha aap sare comment padhte ho to ek reply to banta hai\"   [− Tokens: 22],\n",
              " Sentence: \"hi bhai aap ki film super ho jaye bajrangi bhai jaan\"   [− Tokens: 11],\n",
              " Sentence: \"nahi aayega Yr salman Chalo jagah Khaali karo yaha se : p\"   [− Tokens: 12],\n",
              " Sentence: \"plzz slman ap jrur reply krna hm apka w8 krre h\"   [− Tokens: 11],\n",
              " Sentence: \"5.25 paise diya\"   [− Tokens: 3],\n",
              " Sentence: \"sir ticket k paise ni hai 2 ticket bhejo\"   [− Tokens: 9],\n",
              " Sentence: \"Raksha Shinde SALMAN insha Allah zaror help karenge ...\"   [− Tokens: 9],\n",
              " Sentence: \"Yasmeen Khan . Dimag THIKANE lga kr comnt kr\"   [− Tokens: 9],\n",
              " Sentence: \"Aa to jao id wale din hi dekh lennge ki iss baar bhi record tutna hai pehele wali movies se haha ...... . Being salman khan ? 1000 crores\"   [− Tokens: 29],\n",
              " Sentence: \"Hi salman I wnt ur pic wid ur autograph.am ur big fan.my qustn is aap aisa kya krte h ki apki kbubsirti din b din badhti hi ja rhi h .\"   [− Tokens: 31],\n",
              " Sentence: \"Bhai k sath apun kab se baat karnay ka soch hi raha tha. . Whats App pr aah jana. .\"   [− Tokens: 20],\n",
              " Sentence: \"salman bhai mai aapka bahut bada fan hu aapke sath filmo me kam karna chahte hai\"   [− Tokens: 16],\n",
              " Sentence: \"Mere yeha ek ladka bhi nhi jayega movie dekhne\"   [− Tokens: 9],\n",
              " Sentence: \"Khi BAJRANGI BHAIJAAN KIDNAPDED toh nhi gye ! Ab toh12july ko hi pta chalega .\"   [− Tokens: 15],\n",
              " Sentence: \"jitne v salman ko gaali de rhe hai . sb owaisi ke dogle hai . sala sb galat msg failata hai owaisi supporters\"   [− Tokens: 23],\n",
              " Sentence: \"Tusi bast pm ho modi ji Sade I 'm panjabi\"   [− Tokens: 10],\n",
              " Sentence: \"kya likhu han\"   [− Tokens: 3],\n",
              " Sentence: \"galti tum kar rahe ho aur saja mujhe mil rha hai\"   [− Tokens: 11],\n",
              " Sentence: \"dekho wo aaa gya ................ . fir se ed pr edi lene sbka apna bhaijaan ............... .\"   [− Tokens: 17],\n",
              " Sentence: \"agr aana nhi tha to bolna jroori tha :(\"   [− Tokens: 9],\n",
              " Sentence: \"3.30 pm se bhai video chat karenge yaha pe sb question taiyar rakhna apne\"   [− Tokens: 14],\n",
              " Sentence: \"Salman bhai hum to apne bach pan sey like kartey they abibi kartey hai lykin aapne ek baat kah ke hamey naraaz kardiya\"   [− Tokens: 23],\n",
              " Sentence: \"India ka hal aisa hote jaiega to india may koi educated person nehi nicklegi\"   [− Tokens: 14],\n",
              " Sentence: \"Aur Salman bhai apki hum apka movies nhi dekhne jainge , , , Q k apnea ussme wahiyaad bhagwan ka chalissa gaya ha jiska wajse Muslim ko sarminda hona padege , , , , , Pura mehena yani month , , roza Namaz padne k baad ye sunnege , , , kya bhai apko koi aur movies nhi mila kya\"   [− Tokens: 60],\n",
              " Sentence: \"Kyo modi ji bihar ke yua berojgar hi rhenge . Bihar ki gandi rajniti me sare yua piss rhe h\"   [− Tokens: 20],\n",
              " Sentence: \"De tera aur salman ka character hi waisa hai chip\"   [− Tokens: 10],\n",
              " Sentence: \"Sir bhajrangi bhaijan .... sabse achii film hogi ..... boollywodd mein . ... I wish\"   [− Tokens: 15],\n",
              " Sentence: \"Hiiii me aap ki sab se bati Fan hoooooo .... . ??????? ?\"   [− Tokens: 13],\n",
              " Sentence: \"allah hafiz .... salman\"   [− Tokens: 4],\n",
              " Sentence: \"Pyar mangi to Jaan dengi,milk mango to kher dengi,agaar Kashmir mangi to chir dengi .\"   [− Tokens: 15],\n",
              " Sentence: \"Salman ab hindu bangya he bhayoo koi movie dhkhne nhi jaaye\"   [− Tokens: 11],\n",
              " Sentence: \"md.intjar.malik . bajrangi.bhijane . . i love.you . ( 786 ) . bhijane.apki.film . no : 1 hogi .\"   [− Tokens: 19],\n",
              " Sentence: \"Hum bhuke mur rahe hai sir\"   [− Tokens: 6],\n",
              " Sentence: \"4 baj gaye lekin bhai abi aaye nahi ...\"   [− Tokens: 9],\n",
              " Sentence: \"sallluuuuuuuuuuu aa bhi jao :'(\"   [− Tokens: 5],\n",
              " Sentence: \"Ek rply to kar do salman g ... ab to dekho sab ko pta chal gya ... . lakin aap ko kab pta chalega\"   [− Tokens: 24],\n",
              " Sentence: \"ok come in .... lekin kese salman bhai ... majak nhi kar rahe\"   [− Tokens: 13],\n",
              " Sentence: \"eid musalmaan ki hoti hai\"   [− Tokens: 5],\n",
              " Sentence: \"Are sir aj apke liye 4g internet pk dalwaya hai. . ab aa bhi jao. . ;)\"   [− Tokens: 17],\n",
              " Sentence: \"I luv sallu\"   [− Tokens: 3],\n",
              " Sentence: \"7 mnt or\"   [− Tokens: 3],\n",
              " Sentence: \"Hai salman i ' from idonesia & maley , god\"   [− Tokens: 10],\n",
              " Sentence: \"Delete mat karna himat hy to jawab to\"   [− Tokens: 8],\n",
              " Sentence: \"Aaaaaaa jaaaaaoooooo bhaiiiiiiiiiiiiiiiiiii knha busy hooooo ham wait kr rhe h\"   [− Tokens: 11],\n",
              " Sentence: \"BJP VIJAY hooooooooooooo\"   [− Tokens: 3],\n",
              " Sentence: \"I want it i want it i want itttttttttt ?? ?\"   [− Tokens: 11],\n",
              " Sentence: \"Bhar do jholi meri\"   [− Tokens: 4],\n",
              " Sentence: \"Joy hind joy hindMeri bhatan tuje salamModi ji aapko salam\"   [− Tokens: 10],\n",
              " Sentence: \"Bhai Goli de rahe ho chotey bhai ko\"   [− Tokens: 8],\n",
              " Sentence: \"Bhai ... wait kar rahe h hum sab ... time btaoo yaar\"   [− Tokens: 12],\n",
              " Sentence: \"bhaya ye bhajrangi bhai Jan ko flop krnay k leye ye kaam kya ja raha hy\"   [− Tokens: 16],\n",
              " Sentence: \"Yeh ki yeh namard hai\"   [− Tokens: 5],\n",
              " Sentence: \"Hiiiii , kya yeh dream hai ?\"   [− Tokens: 7],\n",
              " Sentence: \"I do n't like salman khan madharchod randy ka ladka harami kafir\"   [− Tokens: 12],\n",
              " Sentence: \"Jo aap ke sat rat din lga rha\"   [− Tokens: 8],\n",
              " Sentence: \"Kya socha hai shaadi k bare mai\"   [− Tokens: 7],\n",
              " Sentence: \"sare aade tede mere hi kimat me likha hai upar wale ne chun chun ke lga tha tum to sayad sahi hoge lekin nahi\"   [− Tokens: 24],\n",
              " Sentence: \"selfie le lo bhai ke saath\"   [− Tokens: 6],\n",
              " Sentence: \"Fake coment hai koi nahi ane wala 4baje kisi ko reply nahi mila jhot .\"   [− Tokens: 15],\n",
              " Sentence: \"Aur sab kaisa chalra hai\"   [− Tokens: 5],\n",
              " Sentence: \"Hum to hamesa tayaar rehte hain .... bas aapki aane ki deri hoti hai . ......;-)\"   [− Tokens: 16],\n",
              " Sentence: \"bhai mujhe aapki film bajrangi bhaijaan ke gaane bhaut pasand aye\"   [− Tokens: 11],\n",
              " Sentence: \"Bhai aap bimar ho kya ???? bolti bandh kyu haii ? ?\"   [− Tokens: 12],\n",
              " Sentence: \"hello Sallu bhai , kaise ho aaapp bhai ? mei aapka badaa fan huu bhai :)\"   [− Tokens: 16],\n",
              " Sentence: \"mohammed ji kya salman khan ko sachmooch kisine kidnap kiya h pls bataiye na ... .\"   [− Tokens: 16],\n",
              " Sentence: \"Me duwa karta hun ki bhai aap ka ye muvi San ka rekod tod de\"   [− Tokens: 15],\n",
              " Sentence: \"waise bhi bete hm bs yaha ana bs kam kiye hai warna hm aksar yahi raha karte the\"   [− Tokens: 18],\n",
              " Sentence: \"Jise bhi apne profile pic par 1000 + like lena hai add kar ke massege karo only indians\"   [− Tokens: 18],\n",
              " Sentence: \"Kye hal han Salman Bai\"   [− Tokens: 5],\n",
              " Sentence: \"Bhai mujhe bhi kardo nominate plz\"   [− Tokens: 6],\n",
              " Sentence: \"Main aap py qurban\"   [− Tokens: 4],\n",
              " Sentence: \"Salman bhai 1 no\"   [− Tokens: 4],\n",
              " Sentence: \"ho gyi party sabki ... ab aaram karo ... bhai so rhe ha ...\"   [− Tokens: 14],\n",
              " Sentence: \"bhai jaan aap raipur aaoge kya\"   [− Tokens: 6],\n",
              " Sentence: \"Ek zaroori baat he k koi bhi musalmaan bhai salman khan ki ( BAJRANGI BHAIJAAN ) movie dekhne k liye naa jaae . Us harami ne musalmano ko challenge kiya hai k wo ...\"   [− Tokens: 34],\n",
              " Sentence: \"Modi saab g , , galla da krah bnayi jayoge , k kuj kroge v. .\"   [− Tokens: 16],\n",
              " Sentence: \"jab 1 lakh ppl love u love u likhenge how will u reply poor u\"   [− Tokens: 15],\n",
              " Sentence: \"Salman plz cm ?\"   [− Tokens: 4],\n",
              " Sentence: \"hiii mai ok huiii :)\"   [− Tokens: 5],\n",
              " Sentence: \"Salman Khan Tum Kafir ho Muslim larki ko bagatai ho sharam karo aj be teezi see pilnai wala Religion islam hai\"   [− Tokens: 21],\n",
              " Sentence: \"modi g ke jajbe ko koti koti naman\"   [− Tokens: 8],\n",
              " Sentence: \"Sab ko Jana hai uper ok is liye apna dakho salman nahi aaya ga ok aur vo to dog hai na Muslim hai na Hindu hai na vo insan hai sif dog hai ok bye bye\"   [− Tokens: 36],\n",
              " Sentence: \"Plss suno na\"   [− Tokens: 3],\n",
              " Sentence: \"Modi ji desh ka nam bda rhe he .\"   [− Tokens: 9],\n",
              " Sentence: \"bajrangi bhaijaan all time blockbuster\"   [− Tokens: 5],\n",
              " Sentence: \"4pm baje karenge . direct baat mere saath . this is what bogg bosss siad rightly\"   [− Tokens: 16],\n",
              " Sentence: \"3.30 cant wait ....... .\"   [− Tokens: 5],\n",
              " Sentence: \"kha ho aap shona cant wait ..... . :-)\"   [− Tokens: 9],\n",
              " Sentence: \"Abitna bhi kya sharmana\"   [− Tokens: 4],\n",
              " Sentence: \"Yes puri duniya aapke khilaf ku na ho jaye mujhe aapke upar pura bhrosa h or marte dum tak rahega salman bhaijaan love you\"   [− Tokens: 24],\n",
              " Sentence: \"salu bahi sabka bahi salman bahi , , My Supar kahn Salman kahn kick se v suparhit hogi bajrangi bahijaan ,\"   [− Tokens: 21],\n",
              " Sentence: \"4 : 19 ho rhe kha ho bhai\"   [− Tokens: 8],\n",
              " Sentence: \"4 ..... baj gy .... but party abhiii bakiii hai ..... vo bhi saallllluuuu miya bhaijaaan ki ... .\"   [− Tokens: 19],\n",
              " Sentence: \"luv u soooooooo much salman .... aap ke fans hmesha aap ke saath he ...\"   [− Tokens: 15],\n",
              " Sentence: \"Modi ji aap dash kahenhe sbheka diloke P.M.ho\"   [− Tokens: 8],\n",
              " Sentence: \"Bahot ho chuki hain teri dillagi chale bhi aao abb shyam dhalne lagi. . :-)\"   [− Tokens: 15],\n",
              " Sentence: \"abe chirkut logo thoda hawa to aane do itna bheed lga k rkha h chalo baccha log sb shanti se baith jao koi shor nhi machayega bhai aap ek ek krke sb se milo\"   [− Tokens: 34],\n",
              " Sentence: \"Hallo salman vaiya ... .\"   [− Tokens: 5],\n",
              " Sentence: \"Ap sub ki firki le rhe ho kya ' ?\"   [− Tokens: 10],\n",
              " Sentence: \"Apne muje reply kiya to ' aj ki party meri taraf se '\"   [− Tokens: 13],\n",
              " Sentence: \"Lega rhia purei takt k sath sbhi bharrt venseyo ki duaey ap k sath hai\"   [− Tokens: 15],\n",
              " Sentence: \"Asslamalaikum salaman bhai\"   [− Tokens: 3],\n",
              " Sentence: \"Wah ! Jitni sundar geet ke bhao hain utnihi sundar aur sureeli aawaz hai .\"   [− Tokens: 15],\n",
              " Sentence: \"Sory main nhe aasg t main pakistan main ho ?? ?\"   [− Tokens: 11],\n",
              " Sentence: \"Hiii sallu bhai i m ur biggggest fan .......... kya aap bataege ki aapne acting konse acting skool me sikhi ..... plsss bhai tell me\"   [− Tokens: 25],\n",
              " Sentence: \"Bhai rolaoge kya aa v jao\"   [− Tokens: 6],\n",
              " Sentence: \"Saloo bhai plz pak ajao m india nhi aa sakhta : D\"   [− Tokens: 12],\n",
              " Sentence: \"apki aane wali film bajrangi bhaijan suuuuuupppppppeeeeeeerrrrrrrrrr hit ho\"   [− Tokens: 9],\n",
              " Sentence: \"Sir plz JHANSI ki bijli vyavstha thik Krane ki kripa kre , dhnyevad .\"   [− Tokens: 14],\n",
              " Sentence: \"hello chulbul ji. . aye jaldi sbhi intazar kar kr rhe h apka\"   [− Tokens: 13],\n",
              " Sentence: \"Itni energy vaala perhaps he koi p.m.raha ho india ka , aapkey liyye bhagvaan se prey kertey hai , sabka saath ... Sabka vikas .... jai ho\"   [− Tokens: 27],\n",
              " Sentence: \"bhai i m aslo big fan of you . . i m frm kashmirr .. apka bajrangi bhaijaan main kaise experince Raha .. woh bhi kashmir main shooting kr k nd pls replyy aur kaise laga humra kashmir\"   [− Tokens: 38],\n",
              " Sentence: \"Tnx bhai jan leliya\"   [− Tokens: 4],\n",
              " Sentence: \"salman bhai main apka bahut bada fan hu mujhe apki bahut pasand aata hain .\"   [− Tokens: 15],\n",
              " Sentence: \"Wah maja aa gaya .\"   [− Tokens: 5],\n",
              " Sentence: \"bhai kaam se fariq ho jau to bta dena pahle aap\"   [− Tokens: 11],\n",
              " Sentence: \"AAJ mere desh ko anteraatma SE jaga hua honable PM mila\"   [− Tokens: 11],\n",
              " Sentence: \"kuch nahi bas report send kar raha tha\"   [− Tokens: 8],\n",
              " Sentence: \"Salman bhai do n't worry . Aane do salo ko aisa khinch ke denge ki bhool jaayenge ki saans kaha se le aur pa #* e kaha se ... .\"   [− Tokens: 30],\n",
              " Sentence: \"veer ji aa gai mai karooooo start yo yo yo jai salmannnnnn :)\"   [− Tokens: 13],\n",
              " Sentence: \"Superp bhai jaan\"   [− Tokens: 3],\n",
              " Sentence: \"Aaj ki parti salman bhai ki eid ki parti\"   [− Tokens: 9],\n",
              " Sentence: \"i jush hope k wo insaan jald se jald pkra jaye jisne yeh fake pic bnaya ... .\"   [− Tokens: 18],\n",
              " Sentence: \"mobarak ied mobarak ? ?\"   [− Tokens: 5],\n",
              " Sentence: \"koi dekhe na dekhe hum toh apki iss film ko toh zarur jayenge\"   [− Tokens: 13],\n",
              " Sentence: \"ek reply mujhe bi kardo bhai\"   [− Tokens: 6],\n",
              " Sentence: \"Kamal kartey hoo.Jab bhai ayenge tou awaaz tou hougi hii.waiting for the Wright time .\"   [− Tokens: 15],\n",
              " Sentence: \"4 pm ko salman bat krenge\"   [− Tokens: 6],\n",
              " Sentence: \"BHAIJAAN ... KAVVI KOLKATA may aoo . . apni fanzzzz say milne ... already Banjarangi bhaijaan MEGA ... HIT ...\"   [− Tokens: 20],\n",
              " Sentence: \"Kay kahna chah rahi ho\"   [− Tokens: 5],\n",
              " Sentence: \"agr is desh me badlaw lane hai to sampark kre 9451551081 , pe mere pass sujhaw aur tarika dono hai teachero ka vetan bhar bdhate jao jo sote hai collego me soche fir comment kre\"   [− Tokens: 35],\n",
              " Sentence: \"itna intazaar : O :(\"   [− Tokens: 5],\n",
              " Sentence: \"Sir plz reply us ... Hum kab se rah dekh rahe hai apki :(\"   [− Tokens: 14],\n",
              " Sentence: \"kha chale gaye bhai. .\"   [− Tokens: 5],\n",
              " Sentence: \"salman agr tun mery samnay aa gea to ma teri film bna dunga bhenchod apny ap ko tun smjhta kia ha\"   [− Tokens: 21],\n",
              " Sentence: \"Vermaa phone utthao yaar ??? ?\"   [− Tokens: 6],\n",
              " Sentence: \"Kya bat kare aap se bhai sahb aap ne to apna wajod hi badal dia Fir bhi thanks for massage\"   [− Tokens: 20],\n",
              " Sentence: \"aur har bhade ke tattuo se comment karwane wala har SALMAN KHAN musalmaan hota hai\"   [− Tokens: 15],\n",
              " Sentence: \"Salame walekum . bajrangi bhaijan\"   [− Tokens: 5],\n",
              " Sentence: \"hindustan ka raja he bhai\"   [− Tokens: 5],\n",
              " Sentence: \"salman sir aap aiye b nai baat karne :(\"   [− Tokens: 9],\n",
              " Sentence: \"Abey pakistaan ja kutte teri to hindi bhi sahi ni hai\"   [− Tokens: 11],\n",
              " Sentence: \"Bhai help.me plzzz help.me\"   [− Tokens: 4],\n",
              " Sentence: \"Jb chunane ka aadhikr janta ko h to,jb unhe lage ke galat aadmi chuna gaya h to,5yr kyo sahe uske tanasahi,reject kre usa,isse neta janta k pirti jyda jimmadare honge .\"   [− Tokens: 31],\n",
              " Sentence: \"Hindustan ka sher p.m modi jo har country ko apne desh khobiyo se intro karwana chahata haijay hind\"   [− Tokens: 18],\n",
              " Sentence: \"bollywood prem bollywood fitness pleyar bollywood king bollywood god\"   [− Tokens: 9],\n",
              " Sentence: \"sir aap kuch dhyan nahi dete pLz plz plz\"   [− Tokens: 9],\n",
              " Sentence: \"tic toc .. tic toc ... yaar ye time kyu nahi ja raha. .\"   [− Tokens: 14],\n",
              " Sentence: \"Koi rahe ya na rahe mai apke sath hu salman bhai\"   [− Tokens: 11],\n",
              " Sentence: \"Mujhko prr ek ehsan krna k mujhse kv shadi krne ko na kehna :)\"   [− Tokens: 14],\n",
              " Sentence: \"kya bhai aapka ye movie bahubali record tod paeyga\"   [− Tokens: 9],\n",
              " Sentence: \"Salman khan meeting me bzy he kal online aaye ge wo\"   [− Tokens: 11],\n",
              " Sentence: \"Ya allah salman agar nahi ana tha to pehle bola kyu thaa\"   [− Tokens: 12],\n",
              " Sentence: \"Radhika Medan - sirf salman ko chod kr baki sab call krnge tmhe. . ;) :)\"   [− Tokens: 16],\n",
              " Sentence: \"mere sawal ka jawab koi nhi de sakta ;)\"   [− Tokens: 9],\n",
              " Sentence: \"hlooo shalu bhai kya hal h\"   [− Tokens: 6],\n",
              " Sentence: \"Keya sach me salman khan ho mujhe jawab dijiye\"   [− Tokens: 9],\n",
              " Sentence: \"Sir yeh tho sirf aap hi kar sakte hai . Great sir\"   [− Tokens: 12],\n",
              " Sentence: \"Jitni daulat ye neta log vides ghumne me kharch kar dete agar wo garibo me bat de to kitno ka pet bhar jayega\"   [− Tokens: 23],\n",
              " Sentence: \"Me Delhi se hu aapke security gourd se kaha na usne milne diya or n aaptak msg pahuchaya plz meet me\"   [− Tokens: 21],\n",
              " Sentence: \"India ke sabse lokpriy pm modi ji mai aapse request kartahu pm banne ke baad aap mp ke satna nahi aaye please aap jab bhi mp aaye satna aagman ko acsept kar lijiye . Thanku\"   [− Tokens: 35],\n",
              " Sentence: \"Salman bhai i love you nikhil raj hemanshu raj nikhil par frend request kijiye ga salman bhai pls pls pls\"   [− Tokens: 20],\n",
              " Sentence: \"Are kaise pata chalega ke online ho\"   [− Tokens: 7],\n",
              " Sentence: \"sorry year ... sara then salman khan kiy sathe mere thenb barbat ... :'(\"   [− Tokens: 14],\n",
              " Sentence: \"Bhai apni har ek film mai atif ka 1 toh gana jaroor daaalna\"   [− Tokens: 13],\n",
              " Sentence: \"Salman bhai aapne mera hi nai blki sab fans ka dil dukhaya hai\"   [− Tokens: 13],\n",
              " Sentence: \"Salmaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaan ajhooo 4 ghanto se apka wait kar rahi hu\"   [− Tokens: 10],\n",
              " Sentence: \"oh bhai mere luck kitnakharap twtr nahe ho raha\"   [− Tokens: 9],\n",
              " Sentence: \"4 to baj Gaye\"   [− Tokens: 4],\n",
              " Sentence: \"4 bj gye lekin party abi baki h sir wh bhi eid ki\"   [− Tokens: 13],\n",
              " Sentence: \"tum se pyaar < 3 < 3 < 3\"   [− Tokens: 9],\n",
              " Sentence: \"bhai mujhe apna whats app no. do na roj krenge .... .\"   [− Tokens: 12],\n",
              " Sentence: \"bhai bhopal kab aa rahe ho\"   [− Tokens: 6],\n",
              " Sentence: \"chup baith zaleel tu musalman nahi hai aur tu ek c *** tiya hai mada **** d\"   [− Tokens: 17],\n",
              " Sentence: \"Bhai kuch to bta\"   [− Tokens: 4],\n",
              " Sentence: \"Salman khan chahe tera dad musalman hai chahe teri mom hindu hai chahe tu barti hai chahe tu koibi kisi bi chokath ka kuta kuta kuta hai hai hai salman khan tune allah ke name ko istara behudmi nahi karni chahie thi ....... .\"   [− Tokens: 44],\n",
              " Sentence: \"Aap log bahot amir he aapke liye party karna aam baat he par un logo ka kya Jo aapna ilaj bhi nahi karva sakhte jese ke meri friend use apki help chahiye aor aap party kar rahe he aap uski khuch madad karde pliz\"   [− Tokens: 44],\n",
              " Sentence: \"Hum thhak gaye bhai apka intazar kar k kar k hamari ungaliya b duk rahi hai typing karke\"   [− Tokens: 18],\n",
              " Sentence: \"Salaman to harami he ...... tu musalman hoke kafir ban gaya he .... sale kutte ... samne to aa jaan se maar du tuje ... .\"   [− Tokens: 26],\n",
              " Sentence: \"Salmanu mashallah Bahut hamsome ho !!!! khush raho !! !\"   [− Tokens: 10],\n",
              " Sentence: \"Salman g meri asiqi sirf tumse hai\"   [− Tokens: 7],\n",
              " Sentence: \"Ied mubarak ho salmaan g.khuda se dua hai,aapki ye movie bhi badi hit ho,aapki last movis ki tarah .\"   [− Tokens: 19],\n",
              " Sentence: \"Awsome. . miny salman khan .\"   [− Tokens: 6],\n",
              " Sentence: \"oo bhikari ..... kya bola tha tu muje muslaman ki zarurat ni nai abe sale tere jaiso ki musalmano ko zarurt nai hai\"   [− Tokens: 23],\n",
              " Sentence: \"bhaio ye khabar afwah he Muslims ko challenge karne wale\"   [− Tokens: 10],\n",
              " Sentence: \"Ok sallu bhai\"   [− Tokens: 3],\n",
              " Sentence: \"Bhijan mera no 9933742434\"   [− Tokens: 4],\n",
              " Sentence: \"Luv u bhai ... u r so cute .... sbki jaan salman khan ........ . Anitha Parmar\"   [− Tokens: 17],\n",
              " Sentence: \"han # nadim _ shaikh ki amma aaegi. .\"   [− Tokens: 9],\n",
              " Sentence: \"Agar bhai ka 1st day 1st show nahin dekha toh yeh jaan rehne ka kya fayda\"   [− Tokens: 16],\n",
              " Sentence: \"Bhai aap ke may bara fan hu please aap number mujhe mallum nhi\"   [− Tokens: 13],\n",
              " Sentence: \"sallu bhai rockz\"   [− Tokens: 3],\n",
              " Sentence: \"4.10 ho gayi ab to :(\"   [− Tokens: 6],\n",
              " Sentence: \"Agar aaj Maine pyar kiya relies hoti to kitna hit hoti ?\"   [− Tokens: 12],\n",
              " Sentence: \"Sunil ji Brahmand ke Sher hain hamarein Modi Ji\"   [− Tokens: 9],\n",
              " Sentence: \"Md noman teri behan hai wahan pe\"   [− Tokens: 7],\n",
              " Sentence: \"Ramzan ke mahine me film nikalta hai tum kamiyab kaise hoge\"   [− Tokens: 11],\n",
              " Sentence: \"kab aarahe ho\"   [− Tokens: 3],\n",
              " Sentence: \"Salman tera garoo bhi too tega tujhe fakre hai aapne Filme pe dekhe lena eid ka din tum hara filme koye bhi musalman nahi dekhe ga kiya budha to 50 ka hogaya ...\"   [− Tokens: 33],\n",
              " Sentence: \"sir aap kya cheez ho ? kamal !!! !\"   [− Tokens: 9],\n",
              " Sentence: \"# Sallu _ bhai mere ko prsnly msg kr do ek baar ... Bhai # kuchh _ khas hai aap ke lye , whatsapp 8083503086\"   [− Tokens: 25],\n",
              " Sentence: \"buri tarah se flop ho teri mv sale bajrangi jake cast chng kr phle h ####\"   [− Tokens: 16],\n",
              " Sentence: \"aap galat na the , na ho , na hi hoge . bhai aap ki sadi ka intijar pure world ko hai . kab super duper news de rahe ho aap .\"   [− Tokens: 32],\n",
              " Sentence: \"Kal dekhna na bhule\"   [− Tokens: 4],\n",
              " Sentence: \"q jhoot bol raha bhai\"   [− Tokens: 5],\n",
              " Sentence: \"Bhai kha gayab hooo\"   [− Tokens: 4],\n",
              " Sentence: \"Chal jhuta .... answer ek qustion ka b nhi diya\"   [− Tokens: 10],\n",
              " Sentence: \"4 toe hogaya na sir ... .\"   [− Tokens: 7],\n",
              " Sentence: \"Sab log teyar ho jaye bhai jaan aa rahe he ........????????????????????????????????????????????????????? ? 9 ... 8 .... 7 ..... 6 ...... 5 ..... 4 ..... 3 ...... 2 .... .\"   [− Tokens: 29],\n",
              " Sentence: \"i love u salman vai.i always like u vaijan.khuda hamesha apki saath rahega. .\"   [− Tokens: 14],\n",
              " Sentence: \"Hmto chdnge nai bhai ki movie 1st day 1st show\"   [− Tokens: 10],\n",
              " Sentence: \"india digital bana dena modi sarkar pm\"   [− Tokens: 7],\n",
              " Sentence: \"grt step 4grt relation ... nic job sir\"   [− Tokens: 8],\n",
              " Sentence: \"Ab kis baat bheek mang rha rha hath faila kr eid pr\"   [− Tokens: 12],\n",
              " Sentence: \"Ae fake salman Khan he Salman khan aur tiger khan ek adme he jo 2 2 accout use ker rha he sassery ne time wast ker deya\"   [− Tokens: 27],\n",
              " Sentence: \"tere muslman hun te lanat hai\"   [− Tokens: 6],\n",
              " Sentence: \"You r great Salman sir .... Aap 1.Actor baad me ho pehle 1.Achha insan ho .... Ummid hai Aap hindu or muslim ke sath aa rahe apwad jank bayano ko gour nhi farmayege ...\"   [− Tokens: 34],\n",
              " Sentence: \"Bhai song utna acha ni tha jitna socha tha but nyc song\"   [− Tokens: 12],\n",
              " Sentence: \"Roja nehi rakhkar film bana rahahay ... . Haaramka khana kha raha hay\"   [− Tokens: 13],\n",
              " Sentence: \"Salman bhai aap ye comments padhte ya reply karte ho ya nahi ?\"   [− Tokens: 13],\n",
              " Sentence: \"I love u.modi sir jankibhi jarurat ho to mang lena haste haste.dedege aap ka subh sintak\"   [− Tokens: 16],\n",
              " Sentence: \"Super hai bhai suraj is rocking\"   [− Tokens: 6],\n",
              " Sentence: \"Log apna sapna Pura karne ke liye puri duniya ko bhi dokha de sakta h\"   [− Tokens: 15],\n",
              " Sentence: \"Time math chage karo bhai\"   [− Tokens: 5],\n",
              " Sentence: \"Hello modi ji\"   [− Tokens: 3],\n",
              " Sentence: \"4 baj gaye lekin reply abhi baaki hai\"   [− Tokens: 8],\n",
              " Sentence: \"Hello bade bhaijAAN\"   [− Tokens: 3],\n",
              " Sentence: \"Saare jahan se achha hindustaa hamara\"   [− Tokens: 6],\n",
              " Sentence: \"Salman bhai apne apne page pe apna trailer ni dla youtube wala\"   [− Tokens: 12],\n",
              " Sentence: \"Aur eidi main aap chahye\"   [− Tokens: 5],\n",
              " Sentence: \"ram ram bhai salman\"   [− Tokens: 4],\n",
              " Sentence: \"Modi ji aap apna kaam kijiye , kisi ki baat ko mat suniye agar 5 baccho me se do bigad jaayen to bhi paalna to padta hi hai\"   [− Tokens: 28],\n",
              " Sentence: \"Ramadan Mubarak salu bhi. .\"   [− Tokens: 5],\n",
              " Sentence: \"mai life me kya karna chahti hun tumse sadi karne ke alawa\"   [− Tokens: 12],\n",
              " Sentence: \"salman bhai mah ap ki philm jaror dekunga\"   [− Tokens: 8],\n",
              " Sentence: \"sir inshaalllah may ap sy ek bar milon ga.sir ap sy galay mil jao ga.n\"   [− Tokens: 15],\n",
              " Sentence: \"to tera matlb har bura kam karne vala aadmi musalman hota h Great thinking h bhai my midle finger salute u\"   [− Tokens: 21],\n",
              " Sentence: \"insa-allah ye sare record torogi\"   [− Tokens: 5],\n",
              " Sentence: \"Real hero sallu bhai ^_^\"   [− Tokens: 5],\n",
              " Sentence: \"Vai apka koi vi filim hanne dekna nihei chora ... .\"   [− Tokens: 11],\n",
              " Sentence: \"Modi ji namashkarSorry to say but aap jab v kahin Facebook pe kuch share karte hain to status ko English me update karte hai ... Khusi hogi jab aaapka updates hindi me\"   [− Tokens: 32],\n",
              " Sentence: \"Bhai jaan k se hai ap ghar wale k se hai ya film bajrangi bhaijaan qameebi ho gayi mujhe ko i d me add krna ha apko Ramzan ap sub ko Mubarak ho . Saad Khan pakistan Karachi .\"   [− Tokens: 39],\n",
              " Sentence: \"Bhai aa bhi jao ab time ho gya\"   [− Tokens: 8],\n",
              " Sentence: \"Modi ji zindabaad hamare desh ka strong hain joh India ki image badlega\"   [− Tokens: 13],\n",
              " Sentence: \"kutte kutte kutte ... . teri movie flop hogi\"   [− Tokens: 9],\n",
              " Sentence: \"Bhaijaan I 'm eagerly waiting\"   [− Tokens: 5],\n",
              " Sentence: \"wait na karao bhai. . jaldi se aa jao\"   [− Tokens: 9],\n",
              " Sentence: \"Kb bjenge tumhare 4 salman ? ? ?\"   [− Tokens: 8],\n",
              " Sentence: \"Bhai Jaan original kon se fb par ho kiss naam SE hai\"   [− Tokens: 12],\n",
              " Sentence: \"Sir ji namo namoHumari muskile kab door hogiKaushambi ki light aur road ka sudhar pichle 10 year se nahi hua\"   [− Tokens: 20],\n",
              " Sentence: \"Plz come pavan kumar chaturvaidi\"   [− Tokens: 5],\n",
              " Sentence: \"Ek time mein sb sy kaisy krain gy baat\"   [− Tokens: 9],\n",
              " Sentence: \"Hye meri cutey\"   [− Tokens: 3],\n",
              " Sentence: \"Bhai ap jhakas ho pr sab ne body ap ko dekh kar banaaya or ap mote hote ja rahe ho\"   [− Tokens: 20],\n",
              " Sentence: \"sir 4 baj gaye aao na plz\"   [− Tokens: 7],\n",
              " Sentence: \"Help me bhai plzz help.me\"   [− Tokens: 5],\n",
              " Sentence: \"Es i love ka ryply tab tak ayga jab tak tum kuch nhi khta\"   [− Tokens: 14],\n",
              " Sentence: \"Bas ek mnt hai\"   [− Tokens: 4],\n",
              " Sentence: \"Bhaijaan abhi tho 5 baje h Aap jab free ho tab aa jana m tho puri rat Intzar Kar sakta hu ... iam big fan\"   [− Tokens: 25],\n",
              " Sentence: \"bhai aapko bajrang bali ki kasam aa jao\"   [− Tokens: 8],\n",
              " Sentence: \"hello sallu bhaijan ...\"   [− Tokens: 4],\n",
              " Sentence: \"Nhi nhi thanks nhi 3 logo ko aur bta dena\"   [− Tokens: 10],\n",
              " Sentence: \"Yar ashu tm had par kr rhe ho . Plz bs kr yr . . . itna nonsense mt bolo\"   [− Tokens: 20],\n",
              " Sentence: \"Bhay ab mera net pack khatam hone aya he\"   [− Tokens: 9],\n",
              " Sentence: \"Bhai. . do n't worry\"   [− Tokens: 5],\n",
              " Sentence: \"plss salmAn rply kr do ....< 3\"   [− Tokens: 7],\n",
              " Sentence: \"Sir pleaz jalde ao\"   [− Tokens: 4],\n",
              " Sentence: \"fir bye kyo\"   [− Tokens: 3],\n",
              " Sentence: \"Bhai ek bar hamse bat karlo cuz hame ek achievement mil jayega apse bat karne ka\"   [− Tokens: 16],\n",
              " Sentence: \"sabki aan sabki shaan ek humra bhayi jaan salman khan . Best of luck for film salu\"   [− Tokens: 17],\n",
              " Sentence: \"Ur fav footballer ?\"   [− Tokens: 4],\n",
              " Sentence: \"movie to hit tio hogi sure bhai ki movie wo v eidd pe\"   [− Tokens: 13],\n",
              " Sentence: \"Bhai jaan tho bhai jaan he rahage koi aur unke copy nahi ker sakhta yaro yes or no\"   [− Tokens: 18],\n",
              " Sentence: \"Ek bAat apki achchi nhi lgI ... # Salman _ Bhai ... mekO pTa h aP bZy h bt vO bAat apKo ptA nhi chl paegi jab tak aP mekO cntct nhi krenge m apni bAat v clear nhi kr paunga\"   [− Tokens: 41],\n",
              " Sentence: \"hello sir kaise ho plz reply tou de dou aaj plz sir\"   [− Tokens: 12],\n",
              " Sentence: \"Selfie le beta jb marja0ge jb Qaber m ja0ge tb Allah tje dakhega ghtya h0 tm really\"   [− Tokens: 17],\n",
              " Sentence: \"Hey koi meri sister ko pareshan mat karo\"   [− Tokens: 8],\n",
              " Sentence: \"Auno Bhojani teri amma ki chodu replay kaiku kara sale\"   [− Tokens: 10],\n",
              " Sentence: \"yaha sab mental hai. . ok lage raho yaro\"   [− Tokens: 9],\n",
              " Sentence: \"Kiska bhaijan kahan ka Bhai jaan Kutte tu ek nambar shetan , , , , Eed me hi aata he , , kharab karne imman , , ,\"   [− Tokens: 28],\n",
              " Sentence: \"theater me ja k salman ka movie kabhi nahi dekhunga Internet pe 10 din k baad aayega download kar k dekhung !! ! free me\"   [− Tokens: 25],\n",
              " Sentence: \"Great prime minister modi ji jai hind\"   [− Tokens: 7],\n",
              " Sentence: \"Bhai ajao yaar\"   [− Tokens: 3],\n",
              " Sentence: \"aaja sham hone aayi\"   [− Tokens: 4],\n",
              " Sentence: \"music thik nahi hai\"   [− Tokens: 4],\n",
              " Sentence: \"nyc ... mene active kr liya ...\"   [− Tokens: 7],\n",
              " Sentence: \"tym kbka ho gya ... whr r u\"   [− Tokens: 8],\n",
              " Sentence: \"Mere cmnt padhne waalo . Jab is madar chhod ka bajrangi film flop kre to samajh jaana k muslim ka haaye laga ise .\"   [− Tokens: 24],\n",
              " Sentence: \"Kya baat h bhai\"   [− Tokens: 4],\n",
              " Sentence: \"6 miniute ago ..... waiting indias super star salman khan\"   [− Tokens: 10],\n",
              " Sentence: \"Bhar do jholi meri ya Muhammad mujhko Salman bhai se milado\"   [− Tokens: 11],\n",
              " Sentence: \"Sallu bhai aapka no .... chaye\"   [− Tokens: 6],\n",
              " Sentence: \"sala kuti ki olad\"   [− Tokens: 4],\n",
              " Sentence: \"Mullo ko bhagao ... TP mat karo\"   [− Tokens: 7],\n",
              " Sentence: \"pls mane call karo pla pls\"   [− Tokens: 6],\n",
              " Sentence: \"Bhai musalman hone ka to faraz nibha deta brother\"   [− Tokens: 9],\n",
              " Sentence: \"aBHI SE SALMAN BHAI TENSION MAI HAHAHAHAHAHAHA\"   [− Tokens: 7],\n",
              " Sentence: \"modiji duniya k masiha he ... kafi ku6 kiya he or aage bhi karna he ... .\"   [− Tokens: 17],\n",
              " Sentence: \"Aap reply karenge .... ?\"   [− Tokens: 5],\n",
              " Sentence: \"sirr. . khan ho ... goli toh ni de re ? ?\"   [− Tokens: 12],\n",
              " Sentence: \"Bhai kya mazak hi ye 4.6 ho gye\"   [− Tokens: 8],\n",
              " Sentence: \"Bade dhayan se dekh rahe ho\"   [− Tokens: 6],\n",
              " Sentence: \"bahut ho gaya ghumna phirna . ab paani sar se upar jaa raha hai .\"   [− Tokens: 15],\n",
              " Sentence: \"Aaj meri admission thi . But bed nahi mila . Isliye admission ho nahi payi . Isliye main yaha chali ayi . :) :) :)\"   [− Tokens: 25],\n",
              " Sentence: \"bas isi tarah aap age badate rahiye hum aapke sath hai ...\"   [− Tokens: 12],\n",
              " Sentence: \"Salman khan Aapko Aap ka feyn . taranam q stail ma dakhna chahta hai .\"   [− Tokens: 15],\n",
              " Sentence: \"Salman bhaaaiiiii ilovee uuu alooottt ...\"   [− Tokens: 6],\n",
              " Sentence: \"salman bhai , meri ek frnd hai .......... she .... lives ...... in ...... sirsi ..... n ..... aaki ..... bauhat ..... badi ..... fan ..... hai ..... i ..... dont ..... know ..... uske ..... number .... pe ...... wo .... reply ..... nhi ..... kar ..... rhi ...... n ...... wo ...... mujhe ...... seriously .... . lyk ..... karti ..... hai ...... n ..... main .... bhi .... agar ..... mera ..... ye ..... comment ..... aap .... tak .... pauhache ..... den ..... sirf ... aap .... hi ... agar ..... fb ..... pe .... usko .... bol ..... de ..... help ... me .... i .... do n't .... . know ..... main ..... jo ..... likh ..... raha ..... hu .... wo ... sahi .... hai ..... ya .... galat ..... but .... bhagwaan ... kasam ..... dil .... se ..... n .... honestly ..... likh ..... raha ..... hu ..... agar .... aap .... meri ..... help .... kar .... de .... den .... aap .... jo .... bologe ..... wo .... main .... krunga ..... pls .... pls ...... plss ...... Sry. . bhai .... aap soch rhe hoge ki aap mujhe trust kyu kare den pls mera contact\"   [− Tokens: 207],\n",
              " Sentence: \"plllzzzzzz baat kijiye naaa i am waiting kab se\"   [− Tokens: 9],\n",
              " Sentence: \"Sundar ekdam sahi Gaya Hua gana.chhotisi gudiya ko naman\"   [− Tokens: 9],\n",
              " Sentence: \"i love salman sir mera no 7535964415 ap ka bahutt tagda fenss hu i love yy\"   [− Tokens: 16],\n",
              " Sentence: \"dekhate abhi tum hamare liye time dete ho kya to\"   [− Tokens: 10],\n",
              " Sentence: \"Salman gadi aaram se chlana ab wrna jai. . l\"   [− Tokens: 10],\n",
              " Sentence: \"Bhar do jholi meri y Muhammad mujhko Salman sir . S milado , jb tak aap bana d n bigri dr s n jao khli\"   [− Tokens: 25],\n",
              " Sentence: \"Bhai maa aap ka sabse bada fan puri duniya mein aur bhai jodhpur sha ho\"   [− Tokens: 15],\n",
              " Sentence: \"garib ro rahe h or tum jalse kr rhe ho\"   [− Tokens: 10],\n",
              " Sentence: \"where r uu ... bhaiii ... plzz one rplyy mustt onlyy onee :-(\"   [− Tokens: 13],\n",
              " Sentence: \"lovly & nice song .. salman .\"   [− Tokens: 7],\n",
              " Sentence: \"Mare favroute sallu vi ...\"   [− Tokens: 5],\n",
              " Sentence: \"kamaal karte ho\"   [− Tokens: 3],\n",
              " Sentence: \"Salman bhai i knw ur a big celebrity par hakk toh hume bhi milna chaye apse baat krne ka !\"   [− Tokens: 20],\n",
              " Sentence: \"sallu bhaijan.pls aa jo ab\"   [− Tokens: 5],\n",
              " Sentence: \"modi ji pakishtan ko muhtod jabab dena hoga\"   [− Tokens: 8],\n",
              " Sentence: \"bhai fans ka dil na todo aa jao\"   [− Tokens: 8],\n",
              " Sentence: \"Salu g khbi hello hi tou kr lia kr\"   [− Tokens: 9],\n",
              " Sentence: \"Today I am totally confuse ........ bcoz mai ATAL JI Ko best PM manta thaAb lagta hai Modi ji best PM of . BHARAT Bolna parega , , , , jai jai ho\"   [− Tokens: 33],\n",
              " Sentence: \"salo yha kyu apni maiya thukwa rahe ho. . sale chutiye bhaag jao. . ni to ga ** nd paad dunga\"   [− Tokens: 21],\n",
              " Sentence: \"Sab log sun lo salman bhai rat ke 10 bje aayenge\"   [− Tokens: 11],\n",
              " Sentence: \"bhai bhai bhai kaha ho\"   [− Tokens: 5],\n",
              " Sentence: \"Bajrangi bhaijaan 4:30 b baj gaye Kb aaoge. . Bhai kl Mera birthday. . Kal ki party meri taraf se\"   [− Tokens: 20],\n",
              " Sentence: \"Sir main mumbai ja raha hun .... aapke ghar ke pas jarur jaubga\"   [− Tokens: 13],\n",
              " Sentence: \"Eid mubark ho bhai jaan advance mai it 's emerjancy plz\"   [− Tokens: 11],\n",
              " Sentence: \"Kidar ho bhai\"   [− Tokens: 3],\n",
              " Sentence: \"kia hova bhai dya hova time katam ho gya\"   [− Tokens: 9],\n",
              " Sentence: \"Sallu bhai so. gyee kyaaa\"   [− Tokens: 5],\n",
              " Sentence: \"Hloo salu bhai ..... .\"   [− Tokens: 5],\n",
              " Sentence: \"bhai kch hi cmnt me 50000 ko paar kr jyga ab tu hello hye bye bol do zzzzzzzzz\"   [− Tokens: 18],\n",
              " Sentence: \"love yu bhai jaan , , , , , I like yu , , , , , I love yu bhai jaan , , , , , , nice song so sweet handsome parsnalti\"   [− Tokens: 34],\n",
              " Sentence: \"Yehi sahi waqt hai jab hamara imaan azmaaya jayega\"   [− Tokens: 9],\n",
              " Sentence: \"Allah ap ko sada khush rakh . aameen .\"   [− Tokens: 9],\n",
              " Sentence: \"love uu salluuu\"   [− Tokens: 3],\n",
              " Sentence: \"Ab tu jada he bolne lagi hai. . soch kar bat kar warna ...\"   [− Tokens: 14],\n",
              " Sentence: \"Bhaijan watsaap pe aapke bare ma jo chal raha ha wo jhoot ha na.plz reply must\"   [− Tokens: 16],\n",
              " Sentence: \"Tension lene ka nhi bhai aapke fan ki koi kami nhi voh aapki film zaroor dekhenge\"   [− Tokens: 16],\n",
              " Sentence: \"Salman bhai loves us .... so dnt be disappointed . ... ek din bhai se milne ka mauka sab ko milega ...\"   [− Tokens: 22],\n",
              " Sentence: \"4 bj gye bhai ... . aa jao ab\"   [− Tokens: 9],\n",
              " Sentence: \"Salman handsome king\"   [− Tokens: 3],\n",
              " Sentence: \"Bhai hume fool to nahi bana rahe na\"   [− Tokens: 8],\n",
              " Sentence: \"Intzar ...... . ho gye mere salmaan ... . sir ki aae na kuch khabr sir ji aapki ....... .\"   [− Tokens: 20],\n",
              " Sentence: \"salman khan ka aphran ho gya tv pe aa rha h\"   [− Tokens: 11],\n",
              " Sentence: \"Inshallah bhai bajrangi bhaijaan will hit\"   [− Tokens: 6],\n",
              " Sentence: \"my favirat hero salman khan\"   [− Tokens: 5],\n",
              " Sentence: \"bhai ne to popat kar diya\"   [− Tokens: 6],\n",
              " Sentence: \"sallu is bst\"   [− Tokens: 3],\n",
              " Sentence: \"lgta hai bhai ka watch slow hai ;-)\"   [− Tokens: 8],\n",
              " Sentence: \"India 's superheroSALMAN KHAN . N ourJAAN\"   [− Tokens: 7],\n",
              " Sentence: \"Axxa laga aapse baat kar k\"   [− Tokens: 6],\n",
              " Sentence: \"i love u salman khan iam u r big big fan love u u u u u sooooo much sallu , , i miss u very day\"   [− Tokens: 27],\n",
              " Sentence: \"jisko lgta h bhai nahi aaye the ye link kholo or dekho kitne logo ko bhai ne jawab diye livestream.com / fblive / salmankhan\"   [− Tokens: 24],\n",
              " Sentence: \"bhai ap muslim bina kesi hit karoge ye films . .\"   [− Tokens: 11],\n",
              " Sentence: \"Aap katrina se shaadi kyun nahi kar lete ... ? Sallu miya\"   [− Tokens: 12],\n",
              " Sentence: \"Kya baat krni hai msg kr dena. . # Salmankhan\"   [− Tokens: 10],\n",
              " Sentence: \"Salman do n't worry faltu ki abha se apke fan ko fark nhi padega movie mast chalegi\"   [− Tokens: 17],\n",
              " Sentence: \"bhai bolo to sahi\"   [− Tokens: 4],\n",
              " Sentence: \"me apka bhot bda fan hu\"   [− Tokens: 6],\n",
              " Sentence: \"Sat sat naman\"   [− Tokens: 3],\n",
              " Sentence: \"salman yaar sudhar ja bhai Q krta hai gandi herkate yaar\"   [− Tokens: 11],\n",
              " Sentence: \"bhai eid ka gift nhi doge\"   [− Tokens: 6],\n",
              " Sentence: \"Kash kabhi aap humay samjh patay dosti karna ashan hai nibhana mushkil I love you salman khan\"   [− Tokens: 17],\n",
              " Sentence: \"4 bjne hi wali hai\"   [− Tokens: 5],\n",
              " Sentence: \"Bhaijaan main pakistan se ho main apka bohot bra fan ho\"   [− Tokens: 11],\n",
              " Sentence: \"Salman bhai es songs ko movie me bhi dalo plz\"   [− Tokens: 10],\n",
              " Sentence: \"Bhai jaan number btao\"   [− Tokens: 4],\n",
              " Sentence: \"Kamaal karte ho pandey ji whr r u\"   [− Tokens: 8],\n",
              " Sentence: \"raat k 12 bje b kr lenge ... ap aao to sahi\"   [− Tokens: 12],\n",
              " Sentence: \"Jai hind modi sir\"   [− Tokens: 4],\n",
              " Sentence: \"You better reply me Salman ! twitter par nahi toh yahan toh pakka Reply karna padhega lol\"   [− Tokens: 17],\n",
              " Sentence: \"Nice bhai WHATSAAP number 03101419966 palz\"   [− Tokens: 6],\n",
              " Sentence: \"awoo kare baat salman ke sath `- ?\"   [− Tokens: 8],\n",
              " Sentence: \"dashing salman khan . .\"   [− Tokens: 5],\n",
              " Sentence: \"bhai aap tension mtlo humlog aap pr bht trust krte hai yeh films sab ki 300 crs kmayegi ...\"   [− Tokens: 19],\n",
              " Sentence: \"Kya yar hum Milne aaye or aap to mile hi nhi\"   [− Tokens: 11],\n",
              " Sentence: \"Bhai 4 baj gye h\"   [− Tokens: 5],\n",
              " Sentence: \"Mahan bharat ka mahan beta har har modhi\"   [− Tokens: 8],\n",
              " Sentence: \"acha sab ye btao bhai ka sbse bda fan kon hai\"   [− Tokens: 11],\n",
              " Sentence: \"bhaijaan aap awesome hi\"   [− Tokens: 4],\n",
              " Sentence: \"Welcome back Mr pm.ab kitne din rahenge India me ??? ye paisa kisika baap ka nehi hai.hamara hai.hamare paison Se bidesh ja kar ghumte ho saram nehi aati ?? ?\"   [− Tokens: 30],\n",
              " Sentence: \"Bhai love you love you love you love you love you\"   [− Tokens: 11],\n",
              " Sentence: \"Plzzz help me bhai plzz read my comment plzz help me .\"   [− Tokens: 12],\n",
              " Sentence: \"PM ka samman .......... mera samman .... JAY HIND\"   [− Tokens: 9],\n",
              " Sentence: \"o ja gashti k bachey musalman ho k hindu bna hai lanat tere pe\"   [− Tokens: 14],\n",
              " Sentence: \"bhaijaan sultan m negtive role kiska h\"   [− Tokens: 7],\n",
              " Sentence: \"hmm hrt touching moVieeee\"   [− Tokens: 4],\n",
              " Sentence: \"mil gaya bhai aur maine order v kar diya hai Jai bajrang bali\"   [− Tokens: 13],\n",
              " Sentence: \"Mr. Pm hme aap par graw hai . Manish kumar , nasriganj\"   [− Tokens: 12],\n",
              " Sentence: \"Sana khan add karo mujhe\"   [− Tokens: 5],\n",
              " Sentence: \"Mily tujhy Na dukh zindagi mein Phoool ki tarah mehky khuda kary Zinda rahy naam abad tak tera Eid ki khushiyan tujhy Mubarak khuda kary\"   [− Tokens: 25],\n",
              " Sentence: \"aaj ki party Salman ki taraf se\"   [− Tokens: 7],\n",
              " Sentence: \"Yaar frnds aap sabko such mein lagta hai ye salman bhai ki id hai\"   [− Tokens: 14],\n",
              " Sentence: \"ye hai dhasu look ..../ ilu viii\"   [− Tokens: 7],\n",
              " Sentence: \"Nic pic salman\"   [− Tokens: 3],\n",
              " Sentence: \"Choro sir ... ye country kbhi feelings ke respect krna ni seekh sakta ...\"   [− Tokens: 14],\n",
              " Sentence: \"Bhaijaan plz tell plz bhai one comment\"   [− Tokens: 7],\n",
              " Sentence: \"Kamaal karte hoon salman ji aane ka irada hai ya nai\"   [− Tokens: 11],\n",
              " Sentence: \"acha h bhai\"   [− Tokens: 3],\n",
              " Sentence: \"bhai aai jao tame badi door gaau se aako betho hu. .\"   [− Tokens: 12],\n",
              " Sentence: \"Salman Bhai jaan hamare dil me basa hei\"   [− Tokens: 8],\n",
              " Sentence: \"Salman bhai main apki baat ko samj saktahu aur yeh sab jhut hai\"   [− Tokens: 13],\n",
              " Sentence: \"Salman Bhai ..... Mri Bf mjhse jada apko pyar karti h ... or islie mjhe usse bht pyar h kyunki wo mjhse jada apko pyar karti h\"   [− Tokens: 27],\n",
              " Sentence: \"hi salman vai ..... .\"   [− Tokens: 5],\n",
              " Sentence: \"aap ki EID ki party me hum ainge bhai\"   [− Tokens: 9],\n",
              " Sentence: \"bahubali kar rhi h record tod collection\"   [− Tokens: 7],\n",
              " Sentence: \"sir ji ye achi bat nhi he ki aap apne fan se majak kre\"   [− Tokens: 14],\n",
              " Sentence: \"hy bodegurd you my friende.love you ... .\"   [− Tokens: 8],\n",
              " Sentence: \"salman ne reply kiya kya guys\"   [− Tokens: 6],\n",
              " Sentence: \"sachi salman hm to din se wait me hai ki apse baat kar pay\"   [− Tokens: 14],\n",
              " Sentence: \"very good bhai mujy thori bohat samj lg rhi hai\"   [− Tokens: 10],\n",
              " Sentence: \"Aapko bachpan se hi apna best hero mana ....... aapne na aajtak kisi comment ka reply na likes .............. aaj sad hoon main ....... aap bahoot bhoot hit do .... laken main ab sad hoo. . aap mere favroute hero rahoge laken ek baar like ya comment de te to accha rehta ........ thanku\"   [− Tokens: 54],\n",
              " Sentence: \"haha ... . im selected ... < 3 mzaaa aa gya ... umahhhhh bhai luvv uhh\"   [− Tokens: 16],\n",
              " Sentence: \"you are great,Bhaijaan ...... love u bhai,love u bhai,love u bhailove u bhai,love u bhai,love u bhai,love u bhai,love u bhai ,- V E R Y MUCH ... .\"   [− Tokens: 29],\n",
              " Sentence: \"Bhai plz plz jaldi aao\"   [− Tokens: 5],\n",
              " Sentence: \"19 ko eid h or wo apni eidi lene zaroor ayega .\"   [− Tokens: 12],\n",
              " Sentence: \"Javab nahi hai\"   [− Tokens: 3],\n",
              " Sentence: \"Bhai ao na\"   [− Tokens: 3],\n",
              " Sentence: \"In logo pr itna tym kha jo hmse bt kre\"   [− Tokens: 10],\n",
              " Sentence: \"kya aap human being ko hmesha support kroge ?? ?\"   [− Tokens: 10],\n",
              " Sentence: \"bhai dhakka na den\"   [− Tokens: 4],\n",
              " Sentence: \"bhai 4 baj gye\"   [− Tokens: 4],\n",
              " Sentence: \"Mubarak bhai aap ki film 1000 crore kama rahi hai aj ki party aap ki taraf se\"   [− Tokens: 17],\n",
              " Sentence: \"Aap jaisa PM har desh ko milna chahiye,jo apne desh ke future ke liye itni kadi mehnat karke aisi scheme launch kar rhe hai.AAPKO PRAMAAM HAI MERA PM JI .\"   [− Tokens: 30],\n",
              " Sentence: \"maharani laxmi bai , tatya tope , Subhas chandra bos , ajad , Bhagat etc are the true leaders\"   [− Tokens: 19],\n",
              " Sentence: \"Nice bajrangi bhai . . .\"   [− Tokens: 6],\n",
              " Sentence: \"is kutte ki filam dekhne koi bhi schha muslim nhi jayega\"   [− Tokens: 11],\n",
              " Sentence: \"kafir ki film dekhna haram hai\"   [− Tokens: 6],\n",
              " Sentence: \"Bhai i 'm so sad mje yh song site pe nhe mil rhamai kese sunu yh sng\"   [− Tokens: 17],\n",
              " Sentence: \"Ek baar commitment kardi 4:00pm phir kisiki nhi sunnte :)\"   [− Tokens: 10],\n",
              " Sentence: \"m sallu ko etna love krta hu jisko nap ne k liye avi tk kuch ni bna\"   [− Tokens: 17],\n",
              " Sentence: \"We dnt blv sch nonsense keep da gud wrk ! !\"   [− Tokens: 11],\n",
              " Sentence: \"kya karne wale ho kuch soche bhi ya koi phark nahi padta\"   [− Tokens: 12],\n",
              " Sentence: \"Bhai to he to koe gam nae\"   [− Tokens: 7],\n",
              " Sentence: \"Sir it 's 4.o6pm\"   [− Tokens: 4],\n",
              " Sentence: \"Bhai 4 baj gaya bhai kaha ho bhai ? Please reply karo na bhai\"   [− Tokens: 14],\n",
              " Sentence: \"good soch pm narendra modi\"   [− Tokens: 5],\n",
              " Sentence: \"salman sir so rhe h .... do n't disturb\"   [− Tokens: 9],\n",
              " Sentence: \"Plz ply ply plz plz salman sir 1 reply\"   [− Tokens: 9],\n",
              " Sentence: \"aliya zain ko kisi ne dekha h kya ? ?\"   [− Tokens: 10],\n",
              " Sentence: \"app kaha hoo please aa jao na\"   [− Tokens: 7],\n",
              " Sentence: \"Salman ji wakai aap h ki koi fraud bnata h humlogo ko 4 bj gae h\"   [− Tokens: 16],\n",
              " Sentence: \"kal lakshmi mata ki aarti hogi subha ke waqt namaste jii\"   [− Tokens: 11],\n",
              " Sentence: \"Aap Kisi se bhi baat nahi karte ho\"   [− Tokens: 8],\n",
              " Sentence: \"salu miya kaal aa rahe h hum bhaijaan se milne\"   [− Tokens: 10],\n",
              " Sentence: \"salman khan bet hiro mai yuske sath pkchr me ka krna chta hu\"   [− Tokens: 13],\n",
              " Sentence: \"mi ap ki movie ka bhut time se wait kr rhi ccccc\"   [− Tokens: 12],\n",
              " Sentence: \"ji shukriya apne fns s bt krne k liye\"   [− Tokens: 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282,
          "referenced_widgets": [
            "21b2fc14f4304dc8b9a08d963e81e695",
            "18a0f6b3f64d426b9662b6318f817751",
            "ddb23e6d629940f1b39783e413e57df2",
            "4e25081673df45dda0c4f88f9cd44a3b",
            "a229cc173d844d4cb887e7a07c8b8758",
            "f4ffcab3697446e189a7ab5241f98ee3",
            "a600b232e7ba4db198b59db9dabb4212",
            "510aaa69ed6b43fea90462c17c71543a",
            "451a48349f414c2685633b2164ac1701",
            "78814bdf47f34ec6ad250afdc9335021",
            "8bc6ef41fa184e6cb9d2fa057cb38a81",
            "52b76687132c4e288dc770ec5b2dd101",
            "e9bb9e691af247ea9057beecc19688a6",
            "767418201eec4227a0fcf7424e42d259",
            "efe2f9a07a784e92848cf85404c26a51",
            "e12ac806067b43fb9b2c6613a8ab44ec",
            "e920da5ee587448f9b2cb266aef4302d",
            "593c1f63ebc344f885672d672513852a",
            "04a324da78c6458ab7ab66d4134853c8",
            "b7c234dce9ee443a9acbdc002e01846c",
            "f01edf5aeaa9445884318c664c3adcf6",
            "3078c7b8555d4d4b88f00e86dfcf6b05",
            "2ffdab5788e146feb4795762b581c445",
            "aaf20852083a4a0296ac6d9051671227",
            "7d5b6b4398b74f79bdf73d57c2de04e8",
            "d56640e7448a4826aa657ffea32214cb",
            "204a66c9e456417a86c4c74ca28f95bb",
            "07dbcfeb60c248759c07076b43cdc62d",
            "3b46d02bf70a447b9983715605de5bc8",
            "4ec9eff2d248442a8ded1e2a30329cfe",
            "4431246e22824fedb556575713fa5de6",
            "51e74f48ac1a4a86b9b6e365963f3d56",
            "22fe6af5a364402d877aa9924ec40379",
            "866537df10204b689c8546fcf2fc8d78",
            "8a4be2528bb04e87aa34c1b413b7142d",
            "e02d66ff3ed34e4e9fefb2054e99f77c",
            "1ab57fe80a55437ebc2b16fdb75c67b9",
            "3875b134357c465d85a9fa8ff6798bd0",
            "445c56ec9ba84d0ea300f1ccc909f116",
            "9d5b2723a90b48beac6012cfdcdef238",
            "4fe0424c061b4f21b304178309d832ca",
            "11a585c3f05d41f8b140f65b7adf37d5",
            "b48ff1a10d984d8481bf6bdfd4ac73b5",
            "5c595fb8a5e74ac2af6ffa27febc56e7",
            "c88128a47f4a4c8bac7105abbef8567d",
            "ca1b409f0eac49419963c8bb3c2c68d0",
            "90355c4ac92243d48382a5205469d61e",
            "4df425f936cc4daead753e6d8f17264a",
            "1d3834e186a448048698f77829f9f4c5",
            "b329d0e473ae41b0b3ce0369299aae86",
            "0133857b35e24837a6a8b26a85199f90",
            "f83b410dd0ae46c095e13d6eb29e079b",
            "1b1433a2cc2f4175ba0cbcc3b5e71fae",
            "109fee285f4146518539ac374e75f26e",
            "35034a5cb1954774946116bbef377021"
          ]
        },
        "id": "hIwqQ87pI03y",
        "outputId": "c4fed01a-a503-4e26-dc64-db1ec1f702a4"
      },
      "source": [
        "from flair.embeddings import BertEmbeddings\n",
        "import numpy as np\n",
        "embedding_bert = BertEmbeddings(\"bert-base-cased\")\n",
        "\n",
        "X_train_bert = []\n",
        "for sent in X_train_flair:\n",
        "  sent_emb = np.array(embedding_bert.embed(sent)[0])\n",
        "  emb = []\n",
        "  for token in sent_emb:\n",
        "    emb.append(np.array(token.embedding.cpu()))\n",
        "  X_train_bert.append(np.array(emb))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated method __init__. (Use 'TransformerWordEmbeddings' for all transformer-based word embeddings) -- Deprecated since version 0.4.5.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21b2fc14f4304dc8b9a08d963e81e695",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52b76687132c4e288dc770ec5b2dd101",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ffdab5788e146feb4795762b581c445",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "866537df10204b689c8546fcf2fc8d78",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c88128a47f4a4c8bac7105abbef8567d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph1L557dI01B",
        "outputId": "0b5825a4-e21b-4df5-9fca-7acbf9caca8e"
      },
      "source": [
        "EMBEDDINGS_SIZE = X_train_bert[0].shape[1]\n",
        "EMBEDDINGS_SIZE"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3072"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik1NWrUDSdoK"
      },
      "source": [
        "del X_test_flair[629:630]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qo4wlrWTT2A"
      },
      "source": [
        "del y_test[629:630]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVbEXyXI0yL"
      },
      "source": [
        "X_test_bert = []\n",
        "i=0\n",
        "for sent in X_test_flair:\n",
        "  print(sent,i)\n",
        "  print('\\n')\n",
        "  i=i+1\n",
        "  sent_emb = np.array(embedding_bert.embed(sent)[0])\n",
        "  emb = []\n",
        "  for token in sent_emb:\n",
        "    emb.append(np.array(token.embedding.cpu()))\n",
        "  X_test_bert.append(np.array(emb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhxf1RYLJ2ze",
        "outputId": "1d90251c-fec9-4a39-89c0-86546b0ff88f"
      },
      "source": [
        "MAX_SEQ_LEN_train = max([len(tweet.split()) for tweet in X_train])\n",
        "print(MAX_SEQ_LEN_train)\n",
        "\n",
        "MAX_SEQ_LEN_test = max([len(tweet.split()) for tweet in X_test])\n",
        "print(MAX_SEQ_LEN_test)\n",
        "\n",
        "MAX_SEQ_LEN = min(MAX_SEQ_LEN_train, MAX_SEQ_LEN_test)\n",
        "MAX_SEQ_LEN"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n",
            "48\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_zBciYmTs1z",
        "outputId": "bcd82e39-bccd-4d08-e005-3b1ca27d0561"
      },
      "source": [
        "np.save('test_bert', X_test_bert)\n",
        "np.save('train_bert',X_train_bert)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OmJh-4cYliP"
      },
      "source": [
        "#import numpy as np\n",
        "#X_train_bert = np.load(\"train_bert.npy\", allow_pickle=True)\n",
        "#X_test_bert = np.load(\"test_bert.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DmrxUDfJ2w7"
      },
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "emb_list = []\n",
        "for i in X_train_bert:\n",
        "  emb_list.append(torch.tensor(i[:48]))\n",
        "X_train_bert_padded = pad_sequence(emb_list, batch_first=True)\n",
        "\n",
        "emb_list = []\n",
        "for i in X_test_bert:\n",
        "  emb_list.append(torch.tensor(i[:MAX_SEQ_LEN]))\n",
        "X_test_bert_padded = pad_sequence(emb_list, batch_first=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIJHE1ckJ2uq",
        "outputId": "16c68977-7cb0-4375-dc9f-ff5e5bc759cf"
      },
      "source": [
        "y_dct = {'0':0, '1':1,'2':2}\n",
        "print(y_train[:5])\n",
        "\n",
        "for i, sentiment in enumerate(y_train):\n",
        "  y_train[i] = y_dct[sentiment]\n",
        "\n",
        "import numpy as np \n",
        "y_train = np.array(y_train)\n",
        "print(y_train[:5])\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y_train.reshape(-1, 1))\n",
        "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
        "\n",
        "print(y_train[:5])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', '1', '1', '2', '0']\n",
            "[2 1 1 2 0]\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzeMGbglJ2sD",
        "outputId": "9c09b032-3630-4c04-a23b-cf4707aaf866"
      },
      "source": [
        "y_dct = {'0':0, '1':1,'2':2}\n",
        "print(y_test[:5])\n",
        "\n",
        "y_test_int = []\n",
        "for i, sentiment in enumerate(y_test):\n",
        "  y_test_int.append(y_dct[sentiment])\n",
        "\n",
        "import numpy as np \n",
        "y_test_int = np.array(y_test_int)\n",
        "print(y_test_int[:5])\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y_test_int.reshape(-1, 1))\n",
        "y_test= enc.transform(y_test_int.reshape(-1, 1)).toarray()\n",
        "\n",
        "print(y_test[:5])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '2', '1', '2', '0']\n",
            "[0 2 1 2 0]\n",
            "[[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-OiRUo7WpUp"
      },
      "source": [
        "#Bi LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnqHP1j-J2pB",
        "outputId": "265184ea-e4e4-47db-fb60-1d81c56fe09d"
      },
      "source": [
        "\n",
        "!pip install keras_Self_attention\n",
        "!pip install keras_tqdm"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_Self_attention\n",
            "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_Self_attention) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_Self_attention) (2.7.0)\n",
            "Building wheels for collected packages: keras-Self-attention\n",
            "  Building wheel for keras-Self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-Self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=7da0b788c0b903323dbfff370af3d31de9df43d1d63887c2caf95abbee84853e\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
            "Successfully built keras-Self-attention\n",
            "Installing collected packages: keras-Self-attention\n",
            "Successfully installed keras-Self-attention-0.50.0\n",
            "Collecting keras_tqdm\n",
            "  Downloading keras_tqdm-2.0.1-py2.py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_tqdm) (2.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras_tqdm) (4.62.3)\n",
            "Installing collected packages: keras-tqdm\n",
            "Successfully installed keras-tqdm-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsNGCLRLJ2mc"
      },
      "source": [
        "import pickle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Bidirectional\n",
        "from keras import optimizers\n",
        "from keras.layers.recurrent import LSTM\n",
        "import keras\n",
        "from keras.layers import Dropout\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from keras_tqdm import TQDMNotebookCallback"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDGlyzHvVUIT",
        "outputId": "48f2b0f0-37f4-42a5-fcaf-9bfffca3c255"
      },
      "source": [
        "#------------------------------------MODELS------------------------------------------#\n",
        " \n",
        "\"\"\"#### Basic BiLSTM, no appends\n",
        "**MODEL 0.0**:\n",
        "*   BERT\n",
        "*   2 LSTM layer\n",
        "*   4 dense\n",
        "*   2 dense\n",
        "\"\"\"\n",
        "\n",
        "model_Bi_LSTM_1 = Sequential()\n",
        "model_Bi_LSTM_1.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), \n",
        "                                  input_shape=(48, 3072), \n",
        "                                  merge_mode='concat'))\n",
        "model_Bi_LSTM_1.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "model_Bi_LSTM_1.add(Dense(5, activation='softmax'))\n",
        "model_Bi_LSTM_1.add(Dense(3, activation='softmax'))\n",
        "model_Bi_LSTM_1.summary()\n",
        "model_Bi_LSTM_1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_Bi_LSTM_1.fit(x=X_train_bert_padded.cpu().numpy(), \n",
        "                    y=y_train, \n",
        "                    validation_data=(X_test_bert_padded.cpu().numpy(), y_test),\t\n",
        "                    batch_size=128, \n",
        "                    epochs=10, \n",
        "                    shuffle=True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 48, 20)           246640    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 20)               2480      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 105       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 249,243\n",
            "Trainable params: 249,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 74s 2s/step - loss: 1.0182 - accuracy: 0.5063 - val_loss: 1.0084 - val_accuracy: 0.4968\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.9959 - accuracy: 0.5063 - val_loss: 0.9967 - val_accuracy: 0.4968\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.9846 - accuracy: 0.5063 - val_loss: 0.9836 - val_accuracy: 0.5123\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 63s 3s/step - loss: 0.9692 - accuracy: 0.5182 - val_loss: 0.9629 - val_accuracy: 0.5368\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.9518 - accuracy: 0.5543 - val_loss: 0.9447 - val_accuracy: 0.6090\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.9270 - accuracy: 0.5985 - val_loss: 0.9291 - val_accuracy: 0.5961\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.9150 - accuracy: 0.6081 - val_loss: 0.9161 - val_accuracy: 0.5845\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.8853 - accuracy: 0.6271 - val_loss: 0.9279 - val_accuracy: 0.5703\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 59s 2s/step - loss: 0.8744 - accuracy: 0.6162 - val_loss: 0.8902 - val_accuracy: 0.6077\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 60s 2s/step - loss: 0.8485 - accuracy: 0.6513 - val_loss: 0.8747 - val_accuracy: 0.6206\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f196eb7a4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgwDlgwJX6gh"
      },
      "source": [
        "#from keras.models import load_model\n",
        "#model_Bi_LSTM_1.save('my_model_Bi_LSTM_1.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#del model  # deletes the existing model\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "#model_Bi_LSTM_1 = load_model('my_model_Bi_LSTM_1.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZzS_tbSVUF-",
        "outputId": "7a3b0e45-a90f-4c0b-d4f1-5bb016cd767d"
      },
      "source": [
        "model_Bi_LSTM_1.evaluate(X_test_bert_padded.cpu().numpy(), y_test)[1]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 3s 109ms/step - loss: 0.8747 - accuracy: 0.6206\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6206451654434204"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMieeXYbVUDq"
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test_bert_padded.cpu().numpy():\n",
        "  y_pred.append(model_Bi_LSTM_1.predict(np.array([tweet])))\n",
        "\n",
        "#y_pred = np.array([i[0] for i in y_pred])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx7OxLqKeXzm"
      },
      "source": [
        "y_list= list(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOD2kVwqdeoN"
      },
      "source": [
        "def maximum(a, b, c):\n",
        "    if (a >= b) and (a >= c):\n",
        "        largest = 0\n",
        "    elif (b >= a) and (b >= c):\n",
        "        largest = 1\n",
        "    else:\n",
        "        largest = 2\n",
        "    return largest"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8otyS5sZHOf"
      },
      "source": [
        "y_pred_int =[]\n",
        "for i in range(len(y_list)):\n",
        "  y_pred_int.append(maximum((list(list(y_list[i]))[0][0]),(list(list(y_list[i]))[0][1]),(list(list(y_list[i]))[0][2])))\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsXLPlg6e7E1"
      },
      "source": [
        "y_pred = np.array(y_pred_int)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhYjTksAfD2u",
        "outputId": "3c781403-7e85-4210-b0c9-269e6f466ba3"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 1, 1,\n",
              "       0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 2, 2, 0, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 0, 1, 1, 1,\n",
              "       1, 2, 1, 2, 1, 2, 0, 2, 0, 0, 2, 1, 0, 2, 1, 2, 2, 1, 1, 2, 2, 1,\n",
              "       2, 1, 2, 0, 0, 1, 1, 0, 0, 2, 1, 0, 2, 0, 0, 1, 1, 2, 1, 1, 1, 2,\n",
              "       1, 2, 1, 2, 0, 0, 2, 1, 2, 1, 1, 2, 1, 2, 0, 1, 0, 1, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 2, 2,\n",
              "       2, 1, 1, 1, 0, 0, 2, 1, 1, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 1,\n",
              "       1, 2, 2, 2, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
              "       1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 1, 2,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2,\n",
              "       1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 2, 0, 1, 2, 0, 0,\n",
              "       1, 1, 2, 2, 0, 1, 1, 0, 2, 1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1,\n",
              "       2, 2, 2, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 2, 1, 2, 2,\n",
              "       2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       1, 0, 2, 1, 1, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2,\n",
              "       0, 2, 1, 1, 0, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 0, 0,\n",
              "       1, 1, 2, 0, 2, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 2,\n",
              "       1, 0, 1, 0, 0, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 2, 0, 1, 2, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 0, 1, 1, 2, 0, 2, 2, 0, 1, 2, 2, 0, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2,\n",
              "       0, 1, 1, 1, 0, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1,\n",
              "       2, 2, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0,\n",
              "       2, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
              "       2, 1, 2, 0, 2, 1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 0, 2, 1, 2, 1, 0, 1,\n",
              "       1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 2, 1, 2, 2, 0, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4e8ZXVfVUBN",
        "outputId": "8fd8df03-8bc0-446e-9b94-c7d260a084d4"
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative         59       46        14\n",
            "neutral          46      283        56\n",
            "positive         39       93       139\n",
            "\n",
            "\n",
            "Accuracy:  0.6206451612903225\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.41      0.50      0.45       119\n",
            "     neutral       0.67      0.74      0.70       385\n",
            "    positive       0.67      0.51      0.58       271\n",
            "\n",
            "    accuracy                           0.62       775\n",
            "   macro avg       0.58      0.58      0.58       775\n",
            "weighted avg       0.63      0.62      0.62       775\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDJkTQhjWuDw"
      },
      "source": [
        "#Bi LSTM with Self attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csYo0EgNVT-a",
        "outputId": "b6adf4e3-ebf4-49ee-d654-e2b1d66de429"
      },
      "source": [
        "\"\"\"\n",
        "#### Self Attention Library, no appends\n",
        "**MODEL 1.1 SelfAtt**\n",
        "\"\"\"\n",
        "\n",
        "model_Bi_LSTM_att1 = Sequential()\n",
        "model_Bi_LSTM_att1.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(48, 3072), merge_mode='concat'))\n",
        "model_Bi_LSTM_att1.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model_Bi_LSTM_att1.add(Bidirectional(LSTM(5, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "#model_Bi_LSTM_att1.add(Dense(5, activation='softmax'))\n",
        "model_Bi_LSTM_att1.add(Dense(3, activation='softmax'))\n",
        "model_Bi_LSTM_att1.summary()\n",
        "model_Bi_LSTM_att1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_Bi_LSTM_att1.fit(x=X_train_bert_padded.cpu().numpy(), \n",
        "                       y=y_train, \n",
        "                       validation_data=(X_test_bert_padded.cpu().numpy(), y_test),\t\n",
        "                       batch_size=64, \n",
        "                       epochs=10, \n",
        "                       shuffle=True)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 48, 20)           246640    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " seq_self_attention (SeqSelf  (None, 48, 20)           1345      \n",
            " Attention)                                                      \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 10)               1040      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 249,058\n",
            "Trainable params: 249,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "49/49 [==============================] - 83s 1s/step - loss: 1.0161 - accuracy: 0.5060 - val_loss: 0.9763 - val_accuracy: 0.5213\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.9447 - accuracy: 0.5363 - val_loss: 0.9358 - val_accuracy: 0.5535\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.8954 - accuracy: 0.5914 - val_loss: 0.9032 - val_accuracy: 0.5974\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.8411 - accuracy: 0.6258 - val_loss: 0.8761 - val_accuracy: 0.6026\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.8297 - accuracy: 0.6326 - val_loss: 0.8602 - val_accuracy: 0.6103\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.7855 - accuracy: 0.6619 - val_loss: 0.8543 - val_accuracy: 0.6232\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.7542 - accuracy: 0.6723 - val_loss: 0.8384 - val_accuracy: 0.6542\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.7305 - accuracy: 0.6971 - val_loss: 0.8433 - val_accuracy: 0.6387\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.7014 - accuracy: 0.7061 - val_loss: 0.8603 - val_accuracy: 0.6516\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 67s 1s/step - loss: 0.6909 - accuracy: 0.7071 - val_loss: 0.9036 - val_accuracy: 0.6400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f196e930f10>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNiIzpvlfUtc"
      },
      "source": [
        "#from keras.models import load_model\n",
        "#model_Bi_LSTM_att1.save('my_model_Bi_LSTM_att1.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#del model  # deletes the existing model\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "#model_Bi_LSTM_att1 = load_model('my_model_Bi_LSTM_att1.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZRK1vNjVT7z",
        "outputId": "b4162770-c9ea-4a96-fb6c-b093a1056a8a"
      },
      "source": [
        "model_Bi_LSTM_att1.evaluate(X_test_bert_padded.cpu().numpy(), y_test)[1]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 3s 114ms/step - loss: 0.9036 - accuracy: 0.6400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6399999856948853"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN6R6S06VT4w"
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test_bert_padded.cpu().numpy():\n",
        "  y_pred.append(model_Bi_LSTM_att1.predict(np.array([tweet])))\n",
        "\n",
        "#y_pred = np.array([i[0] for i in y_pred])"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrIZ5ew_iCub"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1AhbIJCfUte"
      },
      "source": [
        "y_list= list(y_pred)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG5_TmjwfUtf"
      },
      "source": [
        "y_pred_int =[]\n",
        "for i in range(len(y_list)):\n",
        "  y_pred_int.append(maximum((list(list(y_list[i]))[0][0]),(list(list(y_list[i]))[0][1]),(list(list(y_list[i]))[0][2])))\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNpljRbGfUtg"
      },
      "source": [
        "y_pred_int = np.array(y_pred_int)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5F81-3xfUtg",
        "outputId": "4a9bc26a-7bea-4b43-ffea-be1c12a1579a"
      },
      "source": [
        "y_pred_int"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 1, 1,\n",
              "       1, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1,\n",
              "       1, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 2, 2, 1,\n",
              "       1, 1, 2, 2, 0, 2, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 2,\n",
              "       1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 2, 2, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 2, 1,\n",
              "       2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1, 2,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2,\n",
              "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1,\n",
              "       1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1,\n",
              "       2, 2, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       2, 0, 2, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1,\n",
              "       1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
              "       1, 2, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 0, 1, 1, 0, 0, 2, 2, 0, 1, 2, 2, 0, 1, 1, 1, 1, 2,\n",
              "       1, 1, 1, 2, 2, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       2, 2, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 0, 1,\n",
              "       2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1,\n",
              "       2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1,\n",
              "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzenJZ_LW90R",
        "outputId": "c0816f27-8886-4104-c9cf-bb0b13ee1988"
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred_int), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred_int))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred_int, target_names=target_names))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative         40       64        15\n",
            "neutral          18      336        31\n",
            "positive         23      128       120\n",
            "\n",
            "\n",
            "Accuracy:  0.64\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.49      0.34      0.40       119\n",
            "     neutral       0.64      0.87      0.74       385\n",
            "    positive       0.72      0.44      0.55       271\n",
            "\n",
            "    accuracy                           0.64       775\n",
            "   macro avg       0.62      0.55      0.56       775\n",
            "weighted avg       0.64      0.64      0.62       775\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mwovskcXAHP"
      },
      "source": [
        "#GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbn5IavNXBeA",
        "outputId": "5e7a06a4-3886-49a0-ec2e-f87f5dc198ed"
      },
      "source": [
        "from keras.layers import GRU\n",
        "model_GRU = Sequential()\n",
        "model_GRU.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(48, 3072), merge_mode='concat'))\n",
        "#model_GRU.add(GRU(8, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
        "model_GRU.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model_GRU.add(GRU(8, dropout=0.5, recurrent_dropout=0.5, return_sequences=False))\n",
        "#model_GRU.add(Dense(8, activation='softmax'))\n",
        "model_GRU.add(Dense(3, activation='softmax'))\n",
        "model_GRU.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_GRU.fit(x=X_train_bert_padded.cpu().numpy(), \n",
        "              y=y_train, \n",
        "              validation_data=(X_test_bert_padded.cpu().numpy(), y_test),\t\n",
        "              batch_size=64, epochs=10, shuffle=True)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 74s 1s/step - loss: 1.0217 - accuracy: 0.5056 - val_loss: 0.9781 - val_accuracy: 0.5523\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.9624 - accuracy: 0.5501 - val_loss: 0.9510 - val_accuracy: 0.5613\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.9180 - accuracy: 0.5885 - val_loss: 0.9060 - val_accuracy: 0.5961\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.8749 - accuracy: 0.6046 - val_loss: 0.9068 - val_accuracy: 0.5948\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.8335 - accuracy: 0.6287 - val_loss: 0.8597 - val_accuracy: 0.6052\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.7989 - accuracy: 0.6423 - val_loss: 0.8520 - val_accuracy: 0.6181\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.7646 - accuracy: 0.6607 - val_loss: 0.8459 - val_accuracy: 0.6232\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.7356 - accuracy: 0.6832 - val_loss: 0.8338 - val_accuracy: 0.6387\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.7147 - accuracy: 0.6893 - val_loss: 0.8790 - val_accuracy: 0.6155\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 63s 1s/step - loss: 0.6857 - accuracy: 0.7064 - val_loss: 0.8597 - val_accuracy: 0.6361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1966461a90>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ_c4mTiXCEL",
        "outputId": "bfbdc8bd-472f-49ee-f770-161372245cfd"
      },
      "source": [
        "model_GRU.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 48, 20)           246640    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " seq_self_attention_1 (SeqSe  (None, 48, 20)           1345      \n",
            " lfAttention)                                                    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 8)                 720       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 248,732\n",
            "Trainable params: 248,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V07rRdkfXCBE",
        "outputId": "53488edc-0957-4812-b346-2e8454216730"
      },
      "source": [
        "model_GRU.evaluate(X_test_bert_padded.cpu().numpy(), y_test)[1]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 3s 111ms/step - loss: 0.8597 - accuracy: 0.6361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6361290216445923"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mft0ikDum31g"
      },
      "source": [
        "#from keras.models import load_model\n",
        "#model_GRU.save('my_model_GRU.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#del model  # deletes the existing model\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "#model_GRU = load_model('my_model_GRU.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihCSdAvnXB-P"
      },
      "source": [
        "y_pred = []          \n",
        "\n",
        "for tweet in X_test_bert_padded.cpu().numpy():\n",
        "  y_pred.append(model_GRU.predict(np.array([tweet])))\n",
        "\n",
        "#y_pred = np.array([i[0] for i in y_pred])"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsKtU56_mxCa"
      },
      "source": [
        "y_list= list(y_pred)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlRlhHmnmxCz"
      },
      "source": [
        "y_pred_int =[]\n",
        "for i in range(len(y_list)):\n",
        "  y_pred_int.append(maximum((list(list(y_list[i]))[0][0]),(list(list(y_list[i]))[0][1]),(list(list(y_list[i]))[0][2])))\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0yj_DcymxC0"
      },
      "source": [
        "y_pred = np.array(y_pred_int)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apj7Xu1SmxC0",
        "outputId": "55884f28-47e9-4d0f-ff52-f779c35bc03d"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1,\n",
              "       0, 2, 1, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 2,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 1, 1, 2, 2, 1,\n",
              "       1, 1, 2, 1, 0, 0, 1, 0, 0, 2, 1, 0, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2,\n",
              "       2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 0,\n",
              "       1, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2,\n",
              "       2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 0, 0, 2, 0, 2, 1, 0,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 2, 1,\n",
              "       2, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2,\n",
              "       1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 1, 1, 2, 1,\n",
              "       2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "       0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1,\n",
              "       1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
              "       1, 2, 2, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 2, 0, 2, 1,\n",
              "       1, 0, 1, 0, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 2, 2, 1, 2, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 2, 1, 0,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 2, 1, 1, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2,\n",
              "       1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 2, 1, 1, 2, 1, 0, 1,\n",
              "       2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "       2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
              "       2, 1, 1, 2, 2, 1, 2, 0, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 2, 1, 1, 1,\n",
              "       1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0,\n",
              "       1, 2, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1luCQIkoXKK5",
        "outputId": "d7df6c50-72ba-4203-f6a0-c8fc86448769"
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "target_names=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(y_test_int, y_pred), columns=target_names, index=target_names)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test_int, y_pred))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(y_test_int, y_pred, target_names=target_names))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative         36       64        19\n",
            "neutral          18      319        48\n",
            "positive         17      116       138\n",
            "\n",
            "\n",
            "Accuracy:  0.6361290322580645\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.30      0.38       119\n",
            "     neutral       0.64      0.83      0.72       385\n",
            "    positive       0.67      0.51      0.58       271\n",
            "\n",
            "    accuracy                           0.64       775\n",
            "   macro avg       0.61      0.55      0.56       775\n",
            "weighted avg       0.63      0.64      0.62       775\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAIUJT-OnTAh"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "WcKmOnvknVlE",
        "outputId": "b1af19d5-119f-4054-93fd-69f4ed312f4a"
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.5-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n",
            "Collecting botocore<1.24.0,>=1.23.5\n",
            "  Downloading botocore-1.23.5-py3-none-any.whl (8.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.5->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.5->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 57.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.5 botocore-1.23.5 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GRMKHrfnVhL"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JQBJFHWnVJJ"
      },
      "source": [
        "# Create sentence and label lists\n",
        "sentences = X_train\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "y_dct = {'0':0, '1':1,'2':2}\n",
        "\n",
        "for i, sentiment in enumerate(y_train):\n",
        "  y_train[i] = y_dct[sentiment]\n",
        "\n",
        "import numpy as np \n",
        "labels = np.array(y_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92HCMAn6pUxI",
        "outputId": "cd54a4d4-580c-485b-e565-df64bd1caa6e"
      },
      "source": [
        "labels"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, ..., 0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ5uHuzmnVGn"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blxMSFF8nVEV",
        "outputId": "3d7b6e90-4237-4b9f-ab88-f1161f7ad104"
      },
      "source": [
        "for tweet, bert_tokens, input_id in zip(X_train[:5],tokenized_texts[:5],input_ids[:5]):\n",
        "  print(tweet)\n",
        "  print(bert_tokens)\n",
        "  print(input_id)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pehli bar desh ki \"AAN BAN SHAN\"dikhth he , jispe hame \"NAZ\" he.salam to p.m.\n",
            "['[CLS]', 'pe', '##hli', 'bar', 'des', '##h', 'ki', '\"', 'aa', '##n', 'ban', 'shan', '\"', 'di', '##kh', '##th', 'he', ',', 'ji', '##sp', '##e', 'ham', '##e', '\"', 'na', '##z', '\"', 'he', '.', 'sal', '##am', 'to', 'p', '.', 'm', '.', '[SEP]']\n",
            "[101, 21877, 27766, 3347, 4078, 2232, 11382, 1000, 9779, 2078, 7221, 17137, 1000, 4487, 10023, 2705, 2002, 1010, 10147, 13102, 2063, 10654, 2063, 1000, 6583, 2480, 1000, 2002, 1012, 16183, 3286, 2000, 1052, 1012, 1049, 1012, 102]\n",
            "\n",
            "\n",
            "Sir life me ek baar apko milna he aapko milna he\n",
            "['[CLS]', 'sir', 'life', 'me', 'ek', 'ba', '##ar', 'ap', '##ko', 'mil', '##na', 'he', 'aa', '##p', '##ko', 'mil', '##na', 'he', '[SEP]']\n",
            "[101, 2909, 2166, 2033, 23969, 8670, 2906, 9706, 3683, 23689, 2532, 2002, 9779, 2361, 3683, 23689, 2532, 2002, 102]\n",
            "\n",
            "\n",
            "# 4 baje ge aaaj party abhi baki.wow\n",
            "['[CLS]', '#', '4', 'ba', '##je', 'ge', 'aaa', '##j', 'party', 'ab', '##hi', 'ba', '##ki', '.', 'wow', '[SEP]']\n",
            "[101, 1001, 1018, 8670, 6460, 16216, 13360, 3501, 2283, 11113, 4048, 8670, 3211, 1012, 10166, 102]\n",
            "\n",
            "\n",
            "No problems Salman Bhai aapka koi bhi kuch ukhad nahi sakta bajrangi Bhai jaan suparhit movie hogi\n",
            "['[CLS]', 'no', 'problems', 'salman', 'b', '##hai', 'aa', '##p', '##ka', 'ko', '##i', 'b', '##hi', 'ku', '##ch', 'uk', '##had', 'nah', '##i', 'sa', '##kt', '##a', 'ba', '##j', '##rang', '##i', 'b', '##hai', 'ja', '##an', 'su', '##par', '##hit', 'movie', 'hog', '##i', '[SEP]']\n",
            "[101, 2053, 3471, 28542, 1038, 10932, 9779, 2361, 2912, 12849, 2072, 1038, 4048, 13970, 2818, 2866, 16102, 20976, 2072, 7842, 25509, 2050, 8670, 3501, 24388, 2072, 1038, 10932, 14855, 2319, 10514, 19362, 16584, 3185, 27589, 2072, 102]\n",
            "\n",
            "\n",
            "BEHNCHOD Sahil Rehman Roy. BAAP SE FANDA KAREGA TUJHE TERE INBOX ME THOKUGA\n",
            "['[CLS]', 'be', '##hn', '##cho', '##d', 'sa', '##hil', 're', '##hman', 'roy', '.', 'ba', '##ap', 'se', 'fan', '##da', 'ka', '##re', '##ga', 'tu', '##j', '##he', 'ter', '##e', 'in', '##box', 'me', 'tho', '##ku', '##ga', '[SEP]']\n",
            "[101, 2022, 7295, 9905, 2094, 7842, 19466, 2128, 13890, 6060, 1012, 8670, 9331, 7367, 5470, 2850, 10556, 2890, 3654, 10722, 3501, 5369, 28774, 2063, 1999, 8758, 2033, 27793, 5283, 3654, 102]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTtul35BnU9k",
        "outputId": "3a7828d5-57be-49a5-ba11-65aa50332236"
      },
      "source": [
        "MAX_LEN = max([len(bert_tokens) for bert_tokens in tokenized_texts])\n",
        "print(MAX_LEN)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVPtR0wUnU7B"
      },
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_prSSntnU18"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D-u9fMQnUzW"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnquUrC6oj27",
        "outputId": "024785c2-6ab2-4518-d2b3-c585d8be84e1"
      },
      "source": [
        "print(train_inputs.shape)\n",
        "print(validation_inputs.shape)\n",
        "print(train_labels.shape)\n",
        "print(validation_labels.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2792, 387)\n",
            "(311, 387)\n",
            "(2792,)\n",
            "(311,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhyVv0lBnUwM"
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNwpV3cAnUWr"
      },
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mykIC7J3p1EL"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "#model.cuda()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HIrHiEzp1Bh"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeGS-8wDp0-1",
        "outputId": "aaea276f-d680-4753-f122-a9db58da0298"
      },
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,lr=2e-5,warmup=.1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGsnHB63p08M"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQLkp2ToxNJz"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6yI8Ky9p05X",
        "outputId": "be9e4ceb-82fc-42bb-b313-e074cc1c91aa"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 10\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94RGJMEPp02G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}